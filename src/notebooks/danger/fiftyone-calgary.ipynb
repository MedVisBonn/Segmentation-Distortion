{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c638750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56fa9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "from typing import Iterable, Dict, List, Callable, Tuple, Union, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "import fiftyone as fo\n",
    "import shutil\n",
    "from torchmetrics import Dice\n",
    "\n",
    "sys.path.append('../../')\n",
    "from dataset import CalgaryCampinasDataset\n",
    "from model.unet import UNet2D\n",
    "from model.ae import AE\n",
    "from model.dae import resDAE, AugResDAE\n",
    "from model.wrapper import Frankenstein, ModelAdapter\n",
    "from losses import DiceScoreCalgary, SurfaceDiceCalgary\n",
    "from utils import  epoch_average, UMapGenerator, volume_collate\n",
    "from trainer.unet_trainer import UNetTrainerCalgary\n",
    "from data_utils import get_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd1ede6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config\n",
    "root = '../../../'\n",
    "data_dir = 'data/conp-dataset/projects/calgary-campinas/CC359/Reconstructed/'\n",
    "data_path = root + data_dir\n",
    "debug = False\n",
    "augment = False\n",
    "site = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "513a7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CalgaryCampinasDataset(\n",
    "    data_path=data_path, \n",
    "    site=6,\n",
    "    split='train',\n",
    "    augment=augment, \n",
    "    normalize=True, \n",
    "    debug=debug\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=1, \n",
    "    shuffle=False, \n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47739b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = CalgaryCampinasDataset(\n",
    "    data_path=data_path, \n",
    "    site=6,\n",
    "    split='validation',\n",
    "    augment=augment, \n",
    "    normalize=True, \n",
    "    debug=debug\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    valset, \n",
    "    batch_size=1, \n",
    "    shuffle=False, \n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf2b2cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = CalgaryCampinasDataset(\n",
    "    data_path=data_path, \n",
    "    site=site,\n",
    "    split='all',\n",
    "    augment=augment, \n",
    "    normalize=True, \n",
    "    debug=debug\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=1, \n",
    "    shuffle=False, \n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "672e5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = []\n",
    "for site in [1,2,3,4,5]:\n",
    "    \n",
    "    testloader.append(\n",
    "        DataLoader(\n",
    "            CalgaryCampinasDataset(\n",
    "                data_path=data_path, \n",
    "                site=site,\n",
    "                split='all',\n",
    "                augment=augment, \n",
    "                normalize=True, \n",
    "                debug=debug\n",
    "            ),\n",
    "            batch_size=1, \n",
    "            shuffle=False, \n",
    "            drop_last=False\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d6fd6f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = f'../../../pre-trained-tmp/trained_UNets/calgary_unet0_augmentednnUNet_best.pt'\n",
    "state_dict = torch.load(model_path)['model_state_dict']\n",
    "n_chans_out = 1 \n",
    "seg_model = UNet2D(\n",
    "    n_chans_in=1, \n",
    "    n_chans_out=n_chans_out, \n",
    "    n_filters_init=8,\n",
    "    dropout=False\n",
    ")\n",
    "seg_model.load_state_dict(state_dict)\n",
    "# criterion   = nn.BCEWithLogitsLoss()\n",
    "# eval_metrics = {\n",
    "#     \"Volumetric Dice\": DiceScoreCalgary(),\n",
    "#     \"Surface Dice\": SurfaceDiceCalgary()\n",
    "# }\n",
    "\n",
    "# unet_trainer = UNetTrainerCalgary(\n",
    "#     model=seg_model, \n",
    "#     criterion=criterion, \n",
    "#     train_loader=None, \n",
    "#     valid_loader=None, \n",
    "#     root=root, \n",
    "#     eval_metrics=eval_metrics, \n",
    "#     description=f'calgary_unet0_augmentednnUNet',\n",
    "#     log=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5db3494f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet2D(\n",
       "  (init_path): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (attachment): Identity()\n",
       "  (shortcut0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (down1): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Identity()\n",
       "    (3): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (shortcut1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (down2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Identity()\n",
       "    (3): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (shortcut2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (down3): Sequential(\n",
       "    (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (2): ReLU()\n",
       "    (3): Identity()\n",
       "    (4): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (up3): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (5): ReLU()\n",
       "    (6): Identity()\n",
       "  )\n",
       "  (up2): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (5): ReLU()\n",
       "    (6): Identity()\n",
       "  )\n",
       "  (up1): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (5): ReLU()\n",
       "    (6): Identity()\n",
       "  )\n",
       "  (out_path): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PreActivationND(\n",
       "      (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "      (layer): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "67515608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unet_trainer.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "76c13687",
   "metadata": {},
   "outputs": [],
   "source": [
    "disabled_ids = ['shortcut0', 'shortcut1', 'shortcut2']\n",
    "DAEs = nn.ModuleDict(\n",
    "    {'up3': AugResDAE(\n",
    "        in_channels = 64, \n",
    "        in_dim      = 32,\n",
    "        latent_dim  = 256,\n",
    "        depth       = 3,\n",
    "        block_size  = 4)\n",
    "    }\n",
    ")\n",
    "\n",
    "for layer_id in disabled_ids:\n",
    "    DAEs[layer_id] = nn.Identity()\n",
    "\n",
    "# for i, unet in enumerate(tqdm(unets)):\n",
    "#     #print(f\"Method {method}, Unet {i} - {net_out}\")\n",
    "#     if net_out == 'calgary':\n",
    "#         dataloader = DataLoader(\n",
    "#             datasets[i],\n",
    "#             batch_size=1, \n",
    "#             shuffle=False, \n",
    "#             drop_last=False, \n",
    "#         )\n",
    "\n",
    "model = ModelAdapter(\n",
    "    seg_model=seg_model,\n",
    "    transformations=DAEs,\n",
    "    disabled_ids=disabled_ids,\n",
    "    copy=True\n",
    ")\n",
    "model_path = f'../../../pre-trained-tmp/trained_AEs/calgary_AugResDAE0_localAug_multiImgSingleView_res_balanced_same_best.pt'\n",
    "state_dict = torch.load(model_path)['model_state_dict']\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "# Remove trainiung hooks, add evaluation hooks\n",
    "model.remove_all_hooks()        \n",
    "model.hook_inference_transformations(model.transformations,\n",
    "                           n_samples=1)\n",
    "# Put model in evaluation state\n",
    "model.to(0)\n",
    "model.eval()\n",
    "model.freeze_seg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c6dc1073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xin = img.unsqueeze(0)\n",
    "model.cpu()\n",
    "seg_model.eval()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1a1e1064",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = seg_model(xin)\n",
    "out2 = seg_model(xin)\n",
    "out3 = model.seg_model(xin)[:1]\n",
    "out4 = model(xin)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "104f15f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out1 != out4).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9cca581f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out4 != out3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0a4e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81755707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dice_for_subset(dataloader, fraction, trainer):\n",
    "    \n",
    "    def test_set(dataloader, trainer=trainer, metric=DiceScoreCalgary()):\n",
    "        trainer.model.eval()\n",
    "        scores = []\n",
    "        for batch in dataloader:\n",
    "            input_ = batch['input'].to(trainer.device)\n",
    "            target = batch['target'].to(trainer.device)\n",
    "            net_out = trainer.inference_step(input_)\n",
    "            scores.append(metric(net_out,target).detach().mean().cpu())\n",
    "\n",
    "        return scores\n",
    "\n",
    "    len_    = len(dataloader)\n",
    "    n_cases = int(len_ * fraction)\n",
    "    subset  = trainer.get_subset(dataloader, fraction=fraction, n_cases=n_cases)\n",
    "    loader  = DataLoader(subset, batch_size=1, shuffle=False, drop_last=False)\n",
    "    scores  = test_set(loader)\n",
    "    \n",
    "    return torch.tensor(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6599387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lennartz/repos/Segmentation-Distortion/src/demos/danger/../../utils.py:422: ConvergenceWarning: Number of distinct clusters (520) found smaller than n_clusters (768). Possibly due to duplicate points in X.\n",
      "  kmeans = KMeans(n_clusters=n_cases).fit(kmeans_in)\n"
     ]
    }
   ],
   "source": [
    "seg_model.cuda()\n",
    "scores = []\n",
    "for loader in [train_loader, val_loader, *testloader]:\n",
    "    scores.append(get_dice_for_subset(loader, 0.05, unet_trainer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30a53a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9808),\n",
       " tensor(0.9730),\n",
       " tensor(0.6513),\n",
       " tensor(0.9619),\n",
       " tensor(0.9567),\n",
       " tensor(0.8479),\n",
       " tensor(0.9365)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.mean() for s in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f280b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [\n",
    "     get_subset(\n",
    "        loader.dataset,\n",
    "        seg_model,\n",
    "        criterion=nn.BCEWithLogitsLoss(reduction='none'),\n",
    "        n_cases=25,\n",
    "        fraction=0.05,\n",
    "        batch_size=32\n",
    "    ) for loader in [train_loader, val_loader, *testloader]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc64a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['train', 'validation', *[f'test{k+1}' for k in range(len(testloader))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "18c51e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.delete_non_persistent_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bffc53b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seg_model.cpu()\n",
    "model.cpu()\n",
    "seg_model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e4f7b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "class UMapGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates uncertainty maps from UNets in different ways.\n",
    "    \n",
    "    PyTorch Module to generate uncertainty maps from\n",
    "    * VAE samples\n",
    "    * Entropy in drop out samples\n",
    "    * Entropy in model outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        method  = 'ae',\n",
    "        net_out = 'mms'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.method  = method\n",
    "        self.net_out = net_out\n",
    "        self.m       = nn.Softmax(dim=1) if net_out=='mms' else nn.Sigmoid()\n",
    "        self.ce      = nn.CrossEntropyLoss(reduction='none') if net_out=='mms' else nn.BCEWithLogitsLoss(reduction='none')\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \n",
    "        if self.method == 'none':\n",
    "            return None\n",
    "        \n",
    "        x = x.detach()\n",
    "        \n",
    "        #################################\n",
    "        ### experimental / M&M only   ###\n",
    "        #################################\n",
    "        \n",
    "        if self.method == 'cross_entropy':\n",
    "            umap = self.ce(x[:1], self.m(x[1:]))\n",
    "            umap = umap.mean(dim=0, keepdims=True)\n",
    "            \n",
    "        elif self.method == 'entropy':          \n",
    "            x_prob = self.m(x[:1])\n",
    "            umap = torch.distributions.Categorical(x_prob.permute(0,2,3,1)).entropy()\n",
    "\n",
    "        elif self.method == 'kl_divergence':\n",
    "            x_in = F.log_softmax(x[:1], dim=1)\n",
    "            umap = self.kl(x_in, self.m(x[1:]))\n",
    "            umap = umap.sum(dim=(0,1), keepdims=True)\n",
    "            \n",
    "        elif self.method == 'mse':\n",
    "            x      = self.m(x)\n",
    "            x     -= x.min(dim=1, keepdims=True).values\n",
    "            x     /= x.sum(dim=1, keepdims=True)\n",
    "            umap   = torch.pow(x[:1] - x[1:], 2).mean(0, keepdim=True)\n",
    "            umap   = umap.mean(dim=1, keepdims=True)            \n",
    "            \n",
    "        #################################\n",
    "        ###   old umaps from MICCAI   ###\n",
    "        #################################\n",
    "        \n",
    "        if self.method == 'ae':\n",
    "            if self.net_out == 'mms':                \n",
    "                umap = self.ce(x[:1], self.m(x[1:]))\n",
    "                #umap = umap.mean(dim=(0, 1), keepdims=True)\n",
    "                #print(umap.shape)\n",
    "                umap = umap.mean(dim=0, keepdims=True)\n",
    "#                 x      = self.m(x)\n",
    "#                 x     -= x.min(dim=1, keepdims=True).values\n",
    "#                 x     /= x.sum(dim=1, keepdims=True)\n",
    "#                 umap   = torch.pow(x[:1] - x[1:], 2).mean(0, keepdim=True)\n",
    "#                 umap   = umap.mean(dim=1, keepdims=True)\n",
    "                \n",
    "            elif self.net_out == 'calgary':\n",
    "                x    = torch.sigmoid(x)\n",
    "                umap = torch.pow(x[:1] - x[1:], 2).mean(0, keepdim=True)\n",
    "#                 umap = self.ce(x[:1] - self.m(x[1:]))\n",
    "#                 umap = \n",
    "                \n",
    "                \n",
    "        elif self.method == 'entropy':          \n",
    "\n",
    "            if self.net_out == 'mms':\n",
    "                #print('x', x.shape)\n",
    "                #x_argmax  = torch.argmax(x, dim=1)\n",
    "                #print('2',x_argmax.shape)\n",
    "                #x_one_hot = F.one_hot(x_argmax, num_classes=4).permute(0,3,1,2).float()\n",
    "                #print('3',x_one_hot.shape)\n",
    "                x_softmax = F.softmax(x, dim=1)\n",
    "                #print('soft',x_softmax.shape)\n",
    "                #x_mean    = x_one_hot.mean(dim=0, keepdims=True)\n",
    "                x_mean    = x_softmax.mean(dim=0, keepdims=True)\n",
    "                #print('4',x_mean.shape)\n",
    "                umap = torch.distributions.Categorical(x_mean.permute(0,2,3,1)).entropy()\n",
    "                #print('5',umap.shape)\n",
    "                #umap      = - x_mean * torch.log(x_mean)\n",
    "                #umap      = umap.sum(dim=1, keepdims=True)\n",
    "\n",
    "            elif self.net_out == 'calgary':\n",
    "                x_probs = torch.sigmoid(x[1:])\n",
    "                x_mean  = x_probs.mean(dim=0, keepdims=True)\n",
    "                umap    = - x_mean * torch.log(x_mean) - (1-x_mean) * torch.log(1-x_mean)\n",
    "                \n",
    "        elif self.method == 'probs':\n",
    "            if self.net_out == 'mms':\n",
    "                x_probs = F.softmax(x, dim=1)\n",
    "                umap = torch.distributions.Categorical(x_probs.permute(0,2,3,1)).entropy()\n",
    "                #umap    = - x_probs * torch.log(x_probs)\n",
    "                #umap    = umap.sum(dim=1, keepdims=True)\n",
    "                \n",
    "            elif self.net_out == 'calgary':\n",
    "                x_probs = torch.sigmoid(x)\n",
    "                #print(x_probs.min(), x_probs.max())\n",
    "                #umap = torch.distributions.Categorical(x_probs.permute(0,2,3,1)).entropy()\n",
    "                umap    = - x_probs * torch.log(x_probs+1e-6) - (1-x_probs) * torch.log(1-x_probs+1e-6)\n",
    "        \n",
    "        #print(umap.shape)\n",
    "        return umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3424212a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████| 175/175 [8.8s elapsed, 0s remaining, 20.4 samples/s]       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dataset.delete()\n",
    "except:\n",
    "    print(\"dataset name already available or dataset didnt exist\")\n",
    "\n",
    "\n",
    "# build first dataset\n",
    "n_unets = 2\n",
    "export_dir = os.path.expanduser('~') + '/fiftyone/calgary-dataset'\n",
    "# init dataset\n",
    "dataset = fo.Dataset(name=\"calgary1\")\n",
    "# add group and all Groups we need\n",
    "#dataset.add_group_field(\"group\", default=\"train\")\n",
    "\n",
    "# set mask targets\n",
    "## ground truth targets\n",
    "dataset.mask_targets = {\n",
    "    \"ground_truth\": {0: \"background\",\n",
    "                     1: \"foreground\",}\n",
    "}\n",
    "# error map labels\n",
    "# for i in range(n_unets):\n",
    "#     dataset.mask_targets[f'errormap_it:{i}'] = {1: 'error'}\n",
    "    \n",
    "# make temporary dir for data handling\n",
    "os.makedirs('tmp', exist_ok=True)\n",
    "path = 'tmp/'\n",
    "# init sample list. We save each sample here and add it to the\n",
    "# dataset in the end\n",
    "samples = []\n",
    "# init dice score class\n",
    "# dcs = Dice(num_classes=1, ignore_index=0)\n",
    "# init umap generator\n",
    "umap_generator_baseline = UMapGenerator(method='probs', net_out='calgary')\n",
    "umap_generator_AE = UMapGenerator(method='cross_entropy', net_out='calgary')\n",
    "\n",
    "# itertatively make samples\n",
    "for subset, name in zip(subsets, names):\n",
    "    for i in range(0, len(subset)):\n",
    "        # get data\n",
    "        data = subset[i]\n",
    "        img = data['input']\n",
    "        mask = data['target']\n",
    "        mask[mask < 0] = 0\n",
    "\n",
    "        # save image to disk\n",
    "        img_path  = path + f'img_{name}_{i}.png'\n",
    "        #print(img_path)\n",
    "        img_norm  = img - img.min()\n",
    "        img_norm /= img_norm.max()\n",
    "\n",
    "        save_image(img_norm, img_path)\n",
    "        torch.save(img, path + f'img_{name}_{i}.pt')\n",
    "\n",
    "        sample_image = fo.Sample(\n",
    "            filepath=img_path,\n",
    "            ground_truth=fo.Segmentation(\n",
    "                mask=mask.squeeze().numpy()\n",
    "            ),\n",
    "            tags=[name]\n",
    "        )\n",
    "    \n",
    "        unet_output = seg_model(img.unsqueeze(0))\n",
    "        ae_output   = model(img.unsqueeze(0))\n",
    "        pred_unet = (torch.sigmoid(unet_output) > 0.5) * 1\n",
    "        pred_ae = (torch.sigmoid(ae_output[1:]) > 0.5) * 1\n",
    "        err_map_unet  = (pred_unet != mask)\n",
    "        err_map_ae    = (pred_ae   != mask)\n",
    "        umap_baseline = umap_generator_baseline(unet_output)\n",
    "        umap_ae       = umap_generator_AE(ae_output)\n",
    "        \n",
    "        sample_image[f'pred_unet']  = fo.Segmentation(mask=pred_unet.squeeze().numpy())\n",
    "        sample_image[f'pred_ae']    = fo.Segmentation(mask=pred_ae.squeeze().numpy())\n",
    "        sample_image[f'error_unet'] = fo.Segmentation(mask=err_map_unet.squeeze().numpy())\n",
    "        sample_image[f'error_ae']   = fo.Segmentation(mask=err_map_ae.squeeze().numpy())\n",
    "        sample_image[f'umap_unet']  = fo.Heatmap(map=umap_baseline.squeeze().numpy())\n",
    "        sample_image[f'umap_ae']    = fo.Heatmap(map=umap_ae.squeeze().numpy())\n",
    "\n",
    "        samples.append(sample_image)\n",
    "        \n",
    "# add samples to dataset\n",
    "dataset.add_samples(samples)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3cb538ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:8090/?notebook=True&subscription=aa3ec90f-e885-4d4e-8e29-81fecde56e7d\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe189ce9460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session = fo.launch_app(dataset, port=8090)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40dee76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "6f8c18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.load('../../../results-tmp/results/eval/calgary/pixel/calgary-localAug_multiImgSingleView_res_balanced_same-4-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5f30eb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6256674528121948"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.auc_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ae94d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
