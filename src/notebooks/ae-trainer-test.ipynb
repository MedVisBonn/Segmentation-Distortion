{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "734ab719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "import os, sys\n",
    "import time\n",
    "from typing import Iterable, Dict, Callable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Resize, CenterCrop\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "from batchgenerators.utilities.file_and_folder_operations import *\n",
    "from nnunet.training.dataloading.dataset_loading import *\n",
    "from nnunet.training.network_training.nnUNetTrainerV2 import nnUNetTrainerV2\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils import EarlyStopping, epoch_average, average_metrics\n",
    "from dataset import CalgaryCampinasDataset\n",
    "from model.ae import AE\n",
    "from model.dae import AugResDAE\n",
    "from model.unet import UNet2D\n",
    "from model.wrapper import Frankenstein\n",
    "from losses import MNMCriterionAE, CalgaryCriterionAE, SampleDice, UnetDice\n",
    "from trainer.ae_trainer import AETrainerCalgary, AETrainerACDC\n",
    "\n",
    "\n",
    "nnUnet_prefix = '../../../nnUNet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9e6924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19e53f1a0d2483089d4c2e30943b015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../pre-trained-tmp/trained_AEs/calgary_ae_test0_best.pt\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    'debug': True,\n",
    "    'log': False,\n",
    "    'description': 'calgary_ae_test',\n",
    "    'project': 'MICCAI2023',\n",
    "\n",
    "    # Data params\n",
    "    'n': 0,\n",
    "    'root': '../../',\n",
    "    'data_path': 'data/conp-dataset/projects/calgary-campinas/CC359/Reconstructed/',\n",
    "    'train_site': 6,\n",
    "    'unet': 'calgary_unet',\n",
    "    'channel_out': 8,\n",
    "    \n",
    "    # Hyperparams\n",
    "    'batch_size': 64,\n",
    "    'augment': False,\n",
    "    'difference': True,\n",
    "    'loss': 'huber',\n",
    "    'target': 'output',\n",
    "    'identity_layers': ['shortcut0', 'shortcut1', 'shortcut2'],\n",
    "    \n",
    "    # outputs\n",
    "    'plot_dir': '../experiments/unet/calgary/logs/'\n",
    "}\n",
    "\n",
    "\n",
    "description = cfg['description'] + str(cfg['n'])\n",
    "if cfg['augment']:\n",
    "    description += 'augment'\n",
    "\n",
    "### data loading \n",
    "root      = cfg['root']\n",
    "data_path = root + cfg['data_path']\n",
    "train_set = CalgaryCampinasDataset(data_path=data_path, \n",
    "                                   site=cfg['train_site'], \n",
    "                                   augment=cfg['augment'], \n",
    "                                   normalize=True, \n",
    "                                   split='train', \n",
    "                                   debug=cfg['debug'])\n",
    "\n",
    "valid_set = CalgaryCampinasDataset(data_path=data_path, \n",
    "                                   site=cfg['train_site'], \n",
    "                                   normalize=True, \n",
    "                                   split='validation', \n",
    "                                   debug=cfg['debug'])\n",
    "\n",
    "train_loader = DataLoader(train_set, \n",
    "                          batch_size=cfg['batch_size'], \n",
    "                          shuffle=True, \n",
    "                          drop_last=False,\n",
    "                          num_workers=10)\n",
    "\n",
    "valid_loader = DataLoader(valid_set, \n",
    "                          batch_size=cfg['batch_size'], \n",
    "                          shuffle=False, \n",
    "                          drop_last=False,\n",
    "                          num_workers=10)\n",
    "\n",
    "\n",
    "### Unet\n",
    "unet_path = cfg['unet'] + str(cfg['n'])\n",
    "seg_model = UNet2D(n_chans_in=1, n_chans_out=1, n_filters_init=cfg['channel_out']).to(0)\n",
    "model_path = f'{root}pre-trained-tmp/trained_UNets/{unet_path}_best.pt'\n",
    "state_dict = torch.load(model_path)['model_state_dict']\n",
    "seg_model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "### AE Params\n",
    "layer_ids = ['shortcut0', 'shortcut1', 'shortcut2', 'up3']\n",
    "\n",
    "\n",
    "                   # channel, spatial, latent, depth\n",
    "ae_map   = {'up3': [     64,      32,     64,     2]}\n",
    "\n",
    "\n",
    "AEs = nn.ModuleDict({layer_id: AE(in_channels = ae_map[layer_id][0], \n",
    "                                  in_dim      = ae_map[layer_id][1],\n",
    "                                  latent_dim  = ae_map[layer_id][2],\n",
    "                                  depth       = ae_map[layer_id][3],\n",
    "                                  block_size  = 4) \n",
    "                          for layer_id in layer_ids if layer_id not in cfg['identity_layers']})\n",
    "\n",
    "\n",
    "for layer_id in cfg['identity_layers']:\n",
    "    AEs[layer_id] = nn.Identity()\n",
    "\n",
    "model = Frankenstein(seg_model, \n",
    "                     AEs, \n",
    "                     disabled_ids=cfg['identity_layers'],\n",
    "                     copy=True)\n",
    "\n",
    "criterion = CalgaryCriterionAE(loss=cfg['loss'])\n",
    "\n",
    "eval_metrics = {'Sample Volumetric Dice': SampleDice(data='calgary'),\n",
    "                'UNet Volumetric Dice': UnetDice(data='calgary')}\n",
    "\n",
    "trainer = AETrainerCalgary(model=model, \n",
    "                           unet=seg_model, \n",
    "                           criterion=criterion, \n",
    "                           train_loader=train_loader, \n",
    "                           valid_loader=valid_loader, \n",
    "                           root=root,\n",
    "                           target=cfg['target'],\n",
    "                           description=description,\n",
    "                           lr=1e-4, \n",
    "                           eval_metrics=eval_metrics, \n",
    "                           log=cfg['log'],\n",
    "                           n_epochs=1,\n",
    "                           patience=4) #20\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea53350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n",
      "loading all case properties\n",
      "2023-10-10 08:18:13.187382: Using splits from existing split file: ../../../nnUNet/data/nnUNet_preprocessed/Task500_ACDC/splits_final.pkl\n",
      "2023-10-10 08:18:13.202848: The split file contains 5 splits.\n",
      "2023-10-10 08:18:13.203122: Desired fold for training: 0\n",
      "2023-10-10 08:18:13.203817: This split has 160 training and 40 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5e974b415e4edc89a14d60e8fa73aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "../../pre-trained-tmp/trained_AEs/acdc_ae_test_best.pt\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "        'debug': True,\n",
    "        'log': False,\n",
    "        'description': f'acdc_ae_test', #'mms_vae_for_nnUNet_fc3_0_bs50',\n",
    "        'project': 'MICCAI2023',\n",
    "\n",
    "        # Data params\n",
    "        'n': 0,\n",
    "        'root': '../../',\n",
    "        'data_path': 'data/mnm/',\n",
    "        'train_vendor': 'B',\n",
    "        'unet': f'acdc_unet8_0',\n",
    "        'channel_out': 8,\n",
    "\n",
    "        # Hyperparams\n",
    "        'batch_size': 32,\n",
    "        'augment': False,\n",
    "        'difference': True,\n",
    "        'loss': 'huber',  # huber or ce\n",
    "        'target': 'output', #gt or output\n",
    "        'disabled_ids': ['shortcut0', 'shortcut1', 'shortcut2']\n",
    "}\n",
    "\n",
    "description = cfg['description']\n",
    "root = cfg['root']\n",
    "\n",
    "# Unet\n",
    "unet_path = cfg['unet'] # + str(cfg['n'])\n",
    "unet = UNet2D(n_chans_in=1, n_chans_out=4, n_filters_init=cfg['channel_out']).to(0)\n",
    "model_path = f'{root}pre-trained-tmp/trained_UNets/{unet_path}_best.pt'\n",
    "state_dict = torch.load(model_path)['model_state_dict']\n",
    "unet.load_state_dict(state_dict)\n",
    "\n",
    "### Dataloader\n",
    "## Initialize trainer to get data loaders with data augmentations from training\n",
    "pkl_file          = nnUnet_prefix + 'data/nnUNet_preprocessed/Task500_ACDC/nnUNetPlansv2.1_plans_2D.pkl'\n",
    "fold              = 0\n",
    "output_folder     = nnUnet_prefix + 'results/nnUnet/nnUNet/2d/Task027_ACDC/nnUNetTrainerV2__nnUNetPlansv2.1/'\n",
    "dataset_directory = nnUnet_prefix + 'data/nnUNet_preprocessed/Task500_ACDC'\n",
    "\n",
    "trainer = nnUNetTrainerV2(pkl_file, 0, output_folder, dataset_directory)\n",
    "trainer.initialize()\n",
    "\n",
    "train_loader = trainer.tr_gen\n",
    "valid_loader = trainer.val_gen\n",
    "\n",
    "\n",
    "### VAE Params\n",
    "layer_ids = ['shortcut0', 'shortcut1', 'shortcut2', 'up3']\n",
    "\n",
    "                   #    channel, spatial, latent,  depth, block \n",
    "ae_map   = {'up3': [        64,      32,    128,     2,      4]}\n",
    "\n",
    "cfg['ae_map'] = ae_map\n",
    "if cfg['log']:\n",
    "    run = wandb.init(reinit=True, \n",
    "                     name=cfg['description'],\n",
    "                     project=cfg['project'], \n",
    "                     config=cfg)\n",
    "    cfg = wandb.config\n",
    "\n",
    "\n",
    "AEs = nn.ModuleDict(\n",
    "    {\n",
    "        'up3': AE(\n",
    "            in_channels = ae_map['up3'][0], \n",
    "            in_dim      = ae_map['up3'][1],\n",
    "            latent_dim  = ae_map['up3'][2],\n",
    "            depth       = ae_map['up3'][3],\n",
    "            block_size  = ae_map['up3'][4]\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "for layer_id in cfg['disabled_ids']:\n",
    "     AEs[layer_id] = nn.Identity()\n",
    "\n",
    "\n",
    "model = Frankenstein(unet, \n",
    "                     AEs, \n",
    "                     disabled_ids=cfg['disabled_ids'],\n",
    "                     copy=True)\n",
    "\n",
    "model.cuda()\n",
    "print()\n",
    "criterion    = MNMCriterionAE(loss=cfg['loss'], diff=cfg['difference'])\n",
    "eval_metrics = {'Sample Volumetric Dice': SampleDice(data='MNM'),\n",
    "                'UNet Volumetric Dice': UnetDice(data='MNM')}\n",
    "\n",
    "ae_trainer = AETrainerACDC(model=model, \n",
    "                           unet=unet, \n",
    "                           criterion=criterion, \n",
    "                           train_loader=train_loader, \n",
    "                           valid_loader=valid_loader, \n",
    "                           num_batches_per_epoch=trainer.num_batches_per_epoch,\n",
    "                           num_val_batches_per_epoch=trainer.num_val_batches_per_epoch,\n",
    "                           root=root,\n",
    "                           target=cfg['target'],\n",
    "                           description=description,\n",
    "                           lr=1e-4, \n",
    "                           eval_metrics=eval_metrics, \n",
    "                           log=cfg['log'],\n",
    "                           n_epochs=1, \n",
    "                           patience=8)\n",
    "\n",
    "\n",
    "ae_trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a7c8bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "                 #    channel, spatial, latent,  depth, block \n",
    "dae_map   = {\n",
    "     'shortcut0': [         8,     256,    256,     5,      4],\n",
    "     'shortcut1': [        16,     128,    256,     5,      4],\n",
    "     'shortcut2': [        32,      64,    256,     5,      4],\n",
    "     'up3':       [        64,      32,    256,     5,      4]\n",
    "}\n",
    "\n",
    "# #                         channel, spatial, latent,  depth, block \n",
    "#     dae_map   = {\n",
    "#          'shortcut0': [         8,     256,    256,     3,      4],\n",
    "#     }\n",
    "\n",
    "\n",
    "DAEs = nn.ModuleDict({\n",
    "    key: AugResDAE(\n",
    "        in_channels = dae_map[key][0], \n",
    "        in_dim      = dae_map[key][1],\n",
    "        latent_dim  = dae_map[key][2],\n",
    "        depth       = dae_map[key][3],\n",
    "        block_size  = dae_map[key][4],\n",
    "        residual    = True)\n",
    "    for key in dae_map\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b971e858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26472\n",
      "103760\n",
      "410784\n",
      "1634624\n"
     ]
    }
   ],
   "source": [
    "for key in DAEs:\n",
    "    print(sum(p.numel() for p in DAEs[key].parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d374cac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init.sample.0.weight : (8, 8, 3, 3)\n",
      "init.sample.0.bias : (8,)\n",
      "init.sample.1.weight : (8, 256, 256)\n",
      "init.sample.1.bias : (8, 256, 256)\n",
      "encoder.0.sample.0.weight : (8, 8, 3, 3)\n",
      "encoder.0.sample.0.bias : (8,)\n",
      "encoder.0.sample.1.weight : (8, 256, 256)\n",
      "encoder.0.sample.1.bias : (8, 256, 256)\n",
      "decoder.0.sample.0.weight : (8, 8, 3, 3)\n",
      "decoder.0.sample.0.bias : (8,)\n",
      "decoder.0.sample.1.weight : (8, 256, 256)\n",
      "decoder.0.sample.1.bias : (8, 256, 256)\n",
      "out.weight : (8, 8, 1, 1)\n",
      "out.bias : (8,)\n"
     ]
    }
   ],
   "source": [
    "m = AugResDAE(\n",
    "    in_channels = 8, \n",
    "    in_dim      = 256,\n",
    "    latent_dim  = 256,\n",
    "    depth       = 1,\n",
    "    block_size  = 1,\n",
    "    residual    = True\n",
    ")\n",
    "\n",
    "for l in m.ae.named_parameters():\n",
    "    print(l[0], ':', l[1].detach().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8132c090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788256\n"
     ]
    }
   ],
   "source": [
    "m = AugResDAE(\n",
    "    in_channels = 8, \n",
    "    in_dim      = 128,\n",
    "    latent_dim  = 64,\n",
    "    depth       = 1,\n",
    "    block_size  = 1,\n",
    "    residual    = True\n",
    ")\n",
    "\n",
    "print(sum(p.numel() for p in m.ae.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32f62cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init.sample.0.weight : (8, 8, 3, 3)\n",
      "init.sample.0.bias : (8,)\n",
      "init.sample.1.weight : (8, 128, 128)\n",
      "init.sample.1.bias : (8, 128, 128)\n",
      "encoder.0.sample.0.weight : (8, 8, 3, 3)\n",
      "encoder.0.sample.0.bias : (8,)\n",
      "encoder.0.sample.1.weight : (8, 128, 128)\n",
      "encoder.0.sample.1.bias : (8, 128, 128)\n",
      "decoder.0.sample.0.weight : (8, 8, 3, 3)\n",
      "decoder.0.sample.0.bias : (8,)\n",
      "decoder.0.sample.1.weight : (8, 128, 128)\n",
      "decoder.0.sample.1.bias : (8, 128, 128)\n",
      "out.weight : (8, 8, 1, 1)\n",
      "out.bias : (8,)\n"
     ]
    }
   ],
   "source": [
    "for l in m.ae.named_parameters():\n",
    "    print(l[0], ':', l[1].detach().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02bc2ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AugResDAE(\n",
       "  (ae): ChannelAE(\n",
       "    (init): ConvBlock(\n",
       "      (sample): Sequential(\n",
       "        (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LayerNorm((8, 128, 128), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (encoder): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (sample): Sequential(\n",
       "          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LayerNorm((8, 128, 128), eps=1e-05, elementwise_affine=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (sample): Sequential(\n",
       "          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LayerNorm((8, 128, 128), eps=1e-05, elementwise_affine=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "impo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f1272d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Hi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mHi\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Hi' is not defined"
     ]
    }
   ],
   "source": [
    "Hi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
