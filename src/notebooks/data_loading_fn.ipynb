{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a651242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "from typing import ( \n",
    "    List, \n",
    "    Tuple,\n",
    "    Optional,\n",
    "    Dict\n",
    ")\n",
    "import random\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import functional as F, InterpolationMode\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from batchgenerators.dataloading.data_loader import SlimDataLoaderBase\n",
    "from batchgenerators.transforms.spatial_transforms import (\n",
    "    SpatialTransform, \n",
    "    MirrorTransform\n",
    ")\n",
    "from batchgenerators.transforms.resample_transforms import SimulateLowResolutionTransform\n",
    "from batchgenerators.transforms.noise_transforms import GaussianNoiseTransform, GaussianBlurTransform\n",
    "from batchgenerators.transforms.color_transforms import (\n",
    "    BrightnessMultiplicativeTransform, \n",
    "    ContrastAugmentationTransform, \n",
    "    GammaTransform\n",
    ")\n",
    "from batchgenerators.transforms.utility_transforms import (\n",
    "    RemoveLabelTransform, \n",
    "    RenameTransform, \n",
    "    NumpyToTensor\n",
    ")\n",
    "from batchgenerators.dataloading.data_loader import SlimDataLoaderBase\n",
    "from batchgenerators.dataloading.multi_threaded_augmenter import MultiThreadedAugmenter\n",
    "from batchgenerators.transforms.local_transforms import (\n",
    "    BrightnessGradientAdditiveTransform,\n",
    "    LocalGammaTransform,\n",
    "    LocalSmoothingTransform,\n",
    "    LocalContrastTransform\n",
    ")\n",
    "from batchgenerators.transforms.abstract_transforms import (\n",
    "    Compose,\n",
    "    AbstractTransform\n",
    ")\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import *\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf5e5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = OmegaConf.load('../configs/basic_config.yaml')\n",
    "conf.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7150ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: true\n",
      "wandb:\n",
      "  log: true\n",
      "  project: MICCAI2023-extension\n",
      "fs:\n",
      "  root: ../../\n",
      "data:\n",
      "  calgary:\n",
      "    data_path: data/conp-dataset/projects/calgary-campinas/CC359/Reconstructed/\n",
      "  mnm:\n",
      "    data_path: data/mnm/\n",
      "model:\n",
      "  unet:\n",
      "    calgary:\n",
      "      pre: calgary_unet\n",
      "      n_chans_in: 1\n",
      "      n_filters_in: 8\n",
      "      n_chans_out: 1\n",
      "      training:\n",
      "        save_loc: pre-trained\n",
      "        train_site: 6\n",
      "        augment: true\n",
      "        validation: true\n",
      "        batch_size: 32\n",
      "        num_batches_per_epoch: 250\n",
      "        num_val_batches_per_epoch: 50\n",
      "        epochs: 250\n",
      "        patience: 4\n",
      "        lr: 0.001\n",
      "    acdc:\n",
      "      pre: acdc_unt8_\n",
      "      n_chans_in: 1\n",
      "      n_filters_in: 8\n",
      "      n_chans_out: 4\n",
      "      training:\n",
      "        save_loc: pre-trained\n",
      "        augment: true\n",
      "        validation: true\n",
      "        batch_size: 32\n",
      "        num_batches_per_epoch: 250\n",
      "        num_val_batches_per_epoch: 50\n",
      "        epochs: 250\n",
      "        patience: 4\n",
      "        lr: 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fbf615af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brain_train_loader(\n",
    "    training: str, # unet or dae\n",
    "    cfg: OmegaConf\n",
    "):\n",
    "    return_orig = True if training == 'dae' else False\n",
    "    transform_key = 'local_transforms' if training == 'dae' else 'all_transforms'\n",
    "    \n",
    "    data_path = cfg.fs.root + cfg.data.calgary.data_path\n",
    "    model_cfg = cfg.model.unet.calgary\n",
    "    \n",
    "    train_set = CalgaryCampinasDataset(\n",
    "        data_path=data_path, \n",
    "        site=model_cfg.training.train_site,\n",
    "        augment=False, \n",
    "        normalize=True, \n",
    "        split='train', \n",
    "        debug=cfg.debug\n",
    "    )\n",
    "    \n",
    "    train_loader = MultiImageSingleViewDataLoader(\n",
    "        data=train_set, \n",
    "        batch_size=model_cfg.training.batch_size,\n",
    "        return_orig=return_orig\n",
    "    )\n",
    "    \n",
    "    transforms = Transforms()\n",
    "    train_augmentor = transforms.get_transforms(transform_key)\n",
    "    train_gen = MultiThreadedAugmenter(\n",
    "        data_loader = train_loader, \n",
    "        transform = train_augmentor, \n",
    "        num_processes = 4, \n",
    "        num_cached_per_queue = 2, \n",
    "        seeds=None\n",
    "    )\n",
    "    \n",
    "    if training == 'unet':\n",
    "        valid_set = CalgaryCampinasDataset(\n",
    "            data_path=data_path, \n",
    "            site=model_cfg.training.train_site,\n",
    "            normalize=True, \n",
    "            volume_wise=True,\n",
    "            split='validation'\n",
    "        )\n",
    "\n",
    "        valid_gen = DataLoader(\n",
    "            valid_set, \n",
    "            batch_size=1,\n",
    "            shuffle=False, \n",
    "            drop_last=False, \n",
    "            collate_fn=volume_collate\n",
    "        )\n",
    "        \n",
    "    elif training == 'dae':\n",
    "        valid_set = CalgaryCampinasDataset(\n",
    "            data_path=data_path, \n",
    "            site=model_cfg.training.train_site,\n",
    "            augment=False, \n",
    "            normalize=True, \n",
    "            split='validation', \n",
    "            debug=cfg.debug\n",
    "        )\n",
    "\n",
    "        valid_augmentor = transforms.get_transforms('local_val_transforms')\n",
    "        valid_loader = MultiImageSingleViewDataLoader(\n",
    "            valid_set,\n",
    "            batch_size=model_cfg.training.batch_size,\n",
    "            return_orig=True\n",
    "        )\n",
    "        valid_gen = MultiThreadedAugmenter(\n",
    "            data_loader = valid_loader, \n",
    "            transform = valid_augmentor, \n",
    "            num_processes = 4, \n",
    "            num_cached_per_queue = 2, \n",
    "            seeds=None\n",
    "        )\n",
    "    \n",
    "    return train_gen, valid_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3af76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heart_train_loader(\n",
    "    training: str,\n",
    "    cfg: OmegaConf\n",
    "):\n",
    "    return_orig = True if training == 'dae' else False\n",
    "    transform_key = 'local_transforms' if training == 'dae' else 'all_transforms'\n",
    "    \n",
    "    model_cfg = cfg.model.unet.acdc\n",
    "    \n",
    "    transforms = Transforms()\n",
    "    train_set = ACDCDataset(\n",
    "        data=\"train\",\n",
    "        debug=cfg['debug']\n",
    "    )\n",
    "    train_loader = MultiImageSingleViewDataLoader(\n",
    "        data=train_set, \n",
    "        batch_size=model_cfg.training.batch_size,\n",
    "        return_orig=False\n",
    "    )    \n",
    "    train_augmentor = transforms.get_transforms(transform_key)\n",
    "    train_gen = MultiThreadedAugmenter(\n",
    "        data_loader = train_loader, \n",
    "        transform = train_augmentor, \n",
    "        num_processes = 4, \n",
    "        num_cached_per_queue = 2, \n",
    "        seeds=None\n",
    "    )\n",
    "    \n",
    "    val_set = ACDCDataset(\n",
    "        data=\"val\",\n",
    "        debug=cfg['debug']\n",
    "    )\n",
    "    valid_loader = MultiImageSingleViewDataLoader(\n",
    "        data=val_set, \n",
    "        batch_size=model_cfg.training.batch_size,\n",
    "        return_orig=False\n",
    "    )\n",
    "    valid_augmentor = transforms.get_transforms('io_transforms')\n",
    "    valid_gen = MultiThreadedAugmenter(\n",
    "        data_loader = valid_loader, \n",
    "        transform = valid_augmentor, \n",
    "        num_processes = 4, \n",
    "        num_cached_per_queue = 2, \n",
    "        seeds=None\n",
    "    )\n",
    "    \n",
    "    return train_gen, valid_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4779655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, v = get_brain_train_loader('dae', conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0af9dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n",
      "loading all case properties\n",
      "loading dataset\n",
      "loading all case properties\n"
     ]
    }
   ],
   "source": [
    "t, v = get_heart_train_loader('unet', conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffa9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
