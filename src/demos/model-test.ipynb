{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d9e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from model.ae import AE\n",
    "from model.unet import UNet2D\n",
    "from model.wrapper import Frankenstein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6fb258c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "test input shape: torch.Size([10, 1, 256, 256]) \n",
      "test feature shape: torch.Size([10, 32, 64, 64])\n",
      "Outputs: \n",
      "U-Net output shape: torch.Size([10, 4, 256, 256])\n",
      "AE output shape: torch.Size([10, 32, 64, 64])\n",
      "wrapper output shape w/o hooks:           torch.Size([10, 4, 256, 256])\n",
      "wrapper output shape w   training hooks:  torch.Size([10, 4, 256, 256])\n",
      "wrapper output shape w   inference hooks: torch.Size([20, 4, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# test inputs\n",
    "x_in = torch.zeros((10,1,256,256))\n",
    "feature_in = torch.zeros((10,32,64,64))\n",
    "print(f\"Inputs: \\ntest input shape: {x_in.shape} \\ntest feature shape: {feature_in.shape}\")\n",
    "\n",
    "# - init and test U-Net\n",
    "unet = UNet2D(1, 4, n_filters_init=8)\n",
    "tmp = unet(x_in)\n",
    "print(f\"Outputs: \\nU-Net output shape: {tmp.shape}\")\n",
    "\n",
    "# - init and test AE\n",
    "ae = AE(32, 64)\n",
    "tmp = ae(feature_in)\n",
    "print(f\"AE output shape: {tmp.shape}\")\n",
    "\n",
    "# - init and test wrapper\n",
    "# declare potential attachment points\n",
    "layer_ids = ['shortcut0', 'shortcut1', 'shortcut2', 'up3']\n",
    "\n",
    "# configure ae for specific layer(s)\n",
    "#                         channel, spatial, latent,  depth, block \n",
    "ae_config   = {'up3': [        64,      32,    128,     2,      4]}\n",
    "\n",
    "\n",
    "# set up module dict to pass to \"transformations\"\n",
    "AEs = nn.ModuleDict({'up3': AE(in_channels = ae_config['up3'][0], \n",
    "                                in_dim      = ae_config['up3'][1],\n",
    "                                latent_dim  = ae_config['up3'][2],\n",
    "                                depth       = ae_config['up3'][3],\n",
    "                                block_size  = ae_config['up3'][4])})\n",
    "\n",
    "# for disabled ids, we attach identitdy functions. Since we populate the\n",
    "# batch dimension, we need to make sure that features from different\n",
    "# resolutions have matching batch dimensions even in cases where we do\n",
    "# not alter them.\n",
    "disabled_ids = [layer_id for layer_id in layer_ids if layer_id != 'up3']\n",
    "for layer_id in disabled_ids:\n",
    "    AEs[layer_id] = nn.Identity()\n",
    "\n",
    "# instantiate wrapper class\n",
    "model = Frankenstein(unet, \n",
    "                     AEs, \n",
    "                     disabled_ids=disabled_ids,\n",
    "                     copy=True)\n",
    "\n",
    "# test forward pass without any hooks\n",
    "tmp = model(x_in)\n",
    "print(f\"wrapper output shape w/o hooks:           {tmp.shape}\")\n",
    "\n",
    "# test forward with training hooks\n",
    "model.remove_all_hooks()       \n",
    "model.hook_train_transformations(model.transformations)\n",
    "tmp = model(x_in)\n",
    "print(f\"wrapper output shape w   training hooks:  {tmp.shape}\")\n",
    "\n",
    "# test forward with inference hooks. Sample argument can be used\n",
    "# for transformations with stochastic elements (e.g. VAEs)\n",
    "model.remove_all_hooks()       \n",
    "model.hook_transformations(model.transformations,\n",
    "                           n_samples=1)\n",
    "tmp = model(x_in)\n",
    "print(f\"wrapper output shape w   inference hooks: {tmp.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2525dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE(\n",
       "  (encoder): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (sample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LayerNorm((64, 32, 32), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (sample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LayerNorm((128, 16, 16), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (sample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LayerNorm((256, 8, 8), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (intermediate_conv): ConvBlock(\n",
       "    (sample): Sequential(\n",
       "      (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): LayerNorm((32, 8, 8), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (latent): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  )\n",
       "  (spatial): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=2048, bias=True)\n",
       "    (1): ReshapeLayer()\n",
       "  )\n",
       "  (intermediate_conv_reverse): ConvBlock(\n",
       "    (sample): Sequential(\n",
       "      (0): ConvTranspose2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): LayerNorm((256, 8, 8), eps=1e-05, elementwise_affine=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (sample): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (1): LayerNorm((128, 16, 16), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (sample): Sequential(\n",
       "        (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (1): LayerNorm((64, 32, 32), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (sample): Sequential(\n",
       "        (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (1): LayerNorm((32, 64, 64), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tmp): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
