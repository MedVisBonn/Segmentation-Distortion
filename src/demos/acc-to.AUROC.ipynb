{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0f5a2370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# core\n",
    "import os, sys\n",
    "from typing import Iterable, Dict, List, Callable, Tuple, Union, List\n",
    "\n",
    "# third party\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import SpearmanCorrCoef, AUROC\n",
    "from sklearn.covariance import LedoitWolf #\n",
    "# custom\n",
    "sys.path.append('../')\n",
    "from dataset import (\n",
    "    ACDCDataset, \n",
    "    MNMDataset)\n",
    "from model.unet import UNet2D, UNetEnsemble\n",
    "from model.ae import AE\n",
    "from model.wrapper import Frankenstein\n",
    "from losses import DiceScoreCalgary, DiceScoreMMS #\n",
    "from utils import UMapGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7ad78273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n",
      "loading all case properties\n",
      "loading dataset\n",
      "loading all case properties\n",
      "loading dataset\n",
      "loading all case properties\n"
     ]
    }
   ],
   "source": [
    "### Data - M&M only\n",
    "### - datasets\n",
    "debug = True\n",
    "batch_size = 1\n",
    "test_vendor = 'A'\n",
    "\n",
    "loader = {}\n",
    "# - ACDC train\n",
    "acdc_train = ACDCDataset(data='train', debug=debug)\n",
    "acdc_train_loader = DataLoader(acdc_train, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "loader['train'] = acdc_train_loader\n",
    "# - ACDC val\n",
    "acdc_val = ACDCDataset(data='val', debug=debug)\n",
    "acdc_val_loader = DataLoader(acdc_val, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "loader['val'] = acdc_val_loader\n",
    "# - M&M A\n",
    "mnm_a = MNMDataset(vendor=test_vendor, debug=debug)\n",
    "mnm_a_loader = DataLoader(mnm_a, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "loader['test'] = mnm_a_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee5ecdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Model\n",
    "# segmentation distortion, gonzales\n",
    "# - path\n",
    "root = '../../'\n",
    "# U-Nets\n",
    "middle = 'unet8_' \n",
    "pre = 'acdc'   \n",
    "unet_name = f'{pre}_{middle}{0}'\n",
    "\n",
    "model_path = f'{root}pre-trained-tmp/trained_UNets/{unet_name}_best.pt'\n",
    "state_dict = torch.load(model_path)['model_state_dict']\n",
    "n_chans_out = 4 \n",
    "unet = UNet2D(n_chans_in=1, \n",
    "              n_chans_out=n_chans_out, \n",
    "              n_filters_init=8, \n",
    "              dropout=False)\n",
    "unet.load_state_dict(state_dict)\n",
    "unet.cuda()\n",
    "\n",
    "\n",
    "# - instantiate transformations\n",
    "layer_ids = ['shortcut0', 'shortcut1', 'shortcut2', 'up3']\n",
    "disabled_ids = ['shortcut0', 'shortcut1', 'shortcut2']\n",
    "\n",
    "                   #    channel, spatial, latent,  depth, block \n",
    "ae_map   = {'up3': [        64,      32,    128,     2,      4]}\n",
    "\n",
    "\n",
    "AEs = nn.ModuleDict({'up3': AE(in_channels = ae_map['up3'][0], \n",
    "                                    in_dim      = ae_map['up3'][1],\n",
    "                                    latent_dim  = ae_map['up3'][2],\n",
    "                                    depth       = ae_map['up3'][3],\n",
    "                                    block_size  = ae_map['up3'][4])})\n",
    "\n",
    "for layer_id in disabled_ids:\n",
    "     AEs[layer_id] = nn.Identity()\n",
    "\n",
    "model = Frankenstein(unet, \n",
    "                     AEs, \n",
    "                     disabled_ids=disabled_ids,\n",
    "                     copy=True)\n",
    "model.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "712b001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### eval functions to wirte in\n",
    "\n",
    "class PoolingMahalabonisDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    Evaluation class for OOD and ESCE tasks based on https://arxiv.org/abs/2107.05975.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module, \n",
    "        layer_ids: List[str], \n",
    "        train_loader: DataLoader, \n",
    "        valid_loader: DataLoader,\n",
    "        net_out: str,\n",
    "        criterion: nn.Module = DiceScoreCalgary(),\n",
    "        device: str = 'cuda:0'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device       = device\n",
    "        self.model        = model.to(device)\n",
    "        self.model.eval()\n",
    "        self.layer_ids    = layer_ids\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.net_out      = net_out\n",
    "        self.criterion    = criterion\n",
    "        self.pool         = nn.AvgPool3d(kernel_size=(2,2,2), stride=(2,2,2))\n",
    "        self.auroc        = AUROC(task = 'binary')\n",
    "        \n",
    "        # Init score dict for each layer:\n",
    "        self.latents   = {layer_id: [] for layer_id in self.layer_ids}\n",
    "        self.mu        = {layer_id: None for layer_id in self.layer_ids}\n",
    "        self.sigma_inv = {layer_id: None for layer_id in self.layer_ids}\n",
    "        self.dist      = {layer_id : 0 for layer_id in self.layer_ids}\n",
    "        \n",
    "        self._get_latents()\n",
    "        self._fit_gaussian_to_latents()\n",
    "        \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _get_hook_fn(self, layer_id: str, mode: str = 'collect') -> Callable:\n",
    "        \n",
    "        def hook_fn(module: nn.Module, x: Tuple[Tensor]):\n",
    "            x = x[0]\n",
    "            while torch.prod(torch.tensor(x.shape[1:])) > 1e4:\n",
    "                x = self.pool(x)\n",
    "            x = self.pool(x)\n",
    "            batch_size = x.shape[0]\n",
    "\n",
    "            if mode == 'collect':\n",
    "                self.latents[layer_id].append(x.view(batch_size, -1).detach().cpu())\n",
    "            elif mode == 'single':\n",
    "                self.dist[layer_id] = x.view(batch_size, -1).to(self.device)\n",
    "                \n",
    "        return hook_fn\n",
    "    \n",
    "    \n",
    "    @torch.no_grad()        \n",
    "    def _get_latents(self) -> None:\n",
    "        handles = {}\n",
    "        for layer_id in self.layer_ids:\n",
    "            layer = self.model.get_submodule(layer_id)\n",
    "            hook  = self._get_hook_fn(layer_id, mode='collect')\n",
    "            handles[layer_id] = layer.register_forward_pre_hook(hook)\n",
    "\n",
    "        for batch in self.train_loader:\n",
    "            input_ = batch['input'].to(self.device)\n",
    "            _ = self.model(input_)\n",
    "                \n",
    "        for layer_id in handles:\n",
    "            self.latents[layer_id] = torch.cat(self.latents[layer_id], dim=0)\n",
    "            handles[layer_id].remove()\n",
    "        \n",
    "        \n",
    "    @torch.no_grad()         \n",
    "    def _fit_gaussian_to_latents(self) -> None:\n",
    "        for layer_id in self.layer_ids:\n",
    "            self.mu[layer_id] = self.latents[layer_id].mean(0, keepdims=True).to(self.device)\n",
    "            latents_centered = (self.latents[layer_id] - self.mu[layer_id].cpu()).detach().numpy()\n",
    "            sigma = torch.from_numpy(LedoitWolf().fit(latents_centered).covariance_)\n",
    "            self.sigma_inv[layer_id] = torch.linalg.inv(sigma).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def testset_ood_detection(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        \n",
    "        self.pred = {}\n",
    "        self.target = {}\n",
    "        \n",
    "        valid_dists = {layer_id : [] for layer_id in self.layer_ids}\n",
    "        for batch in self.valid_loader:\n",
    "            input_ = batch['input']\n",
    "            #print(input_.shape)\n",
    "            if self.net_out == 'calgary':\n",
    "                dist_volume = []\n",
    "                for input_chunk in input_:\n",
    "                    dist, _ = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                    dist_volume.append(dist.copy())\n",
    "                dist = default_collate(dist_volume)\n",
    "            elif self.net_out == 'mms': \n",
    "                dist, _ = self.forward(input_.to(self.device))\n",
    "            for layer_id in self.layer_ids:\n",
    "                if self.net_out == 'calgary':\n",
    "                    valid_dists[layer_id].append(dist[layer_id].mean())\n",
    "                elif self.net_out == 'mms':\n",
    "                    valid_dists[layer_id].append(dist[layer_id])\n",
    "        self.valid_dists = valid_dists\n",
    "        self.valid_labels = {layer_id: torch.zeros(len(self.valid_dists[layer_id]), dtype=torch.uint8) \n",
    "                             for layer_id in self.layer_ids}\n",
    "        #print(len(self.valid_dists['up3']), len(self.valid_labels['up3']))\n",
    "            \n",
    "#             self.thresholds = {layer_id : 0 for layer_id in self.layer_ids}\n",
    "#             for layer_id in self.layer_ids:\n",
    "#                 if self.net_out == 'calgary':\n",
    "#                     valid_dists[layer_id] = torch.tensor(valid_dists[layer_id]).cpu()\n",
    "#                 elif self.net_out == 'mms':\n",
    "#                     valid_dists[layer_id] = torch.cat(valid_dists[layer_id], dim=0).cpu()\n",
    "#                 self.thresholds[layer_id] = torch.sort(valid_dists[layer_id])[0][len(valid_dists[layer_id]) - (len(valid_dists[layer_id]) // 20) - 1]\n",
    "                \n",
    "                    \n",
    "        test_dists = {layer_id : [] for layer_id in self.layer_ids}\n",
    "        for batch in test_loader:\n",
    "            input_ = batch['input']\n",
    "            if self.net_out == 'calgary':\n",
    "                dist_volume = []\n",
    "                for input_chunk in input_:\n",
    "                    dist, _ = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                    dist_volume.append(dist.copy())\n",
    "                dist = default_collate(dist_volume)\n",
    "            elif self.net_out == 'mms': \n",
    "                dist, _ = self.forward(input_.to(self.device))\n",
    "            for layer_id in self.layer_ids:\n",
    "                if self.net_out == 'calgary':\n",
    "                    test_dists[layer_id].append(dist[layer_id].mean())\n",
    "                elif self.net_out == 'mms':    \n",
    "                    test_dists[layer_id].append(dist[layer_id])\n",
    "        \n",
    "        self.test_dists = test_dists\n",
    "        self.test_labels = {layer_id: torch.ones(len(self.test_dists[layer_id]), dtype=torch.uint8) \n",
    "                             for layer_id in self.layer_ids}\n",
    "            \n",
    "            \n",
    "        AUROC = {layer_id : 0 for layer_id in self.layer_ids}\n",
    "        for layer_id in self.layer_ids:\n",
    "            if self.net_out == 'calgary':\n",
    "                self.valid_dists[layer_id] = torch.tensor(self.valid_dists[layer_id]).cpu()\n",
    "                self.test_dists[layer_id]  = torch.tensor(self.test_dists[layer_id]).cpu()\n",
    "            elif self.net_out == 'mms':\n",
    "                self.valid_dists[layer_id] = torch.cat(self.valid_dists[layer_id], dim=0).cpu()\n",
    "                self.test_dists[layer_id]  = torch.cat(self.test_dists[layer_id], dim=0).cpu()\n",
    "            self.pred[layer_id]   = torch.cat([self.valid_dists[layer_id], self.test_dists[layer_id]]).squeeze()\n",
    "            self.target[layer_id] = torch.cat([self.valid_labels[layer_id], self.test_labels[layer_id]]).squeeze()\n",
    "            \n",
    "            print(self.pred[layer_id].shape, self.target[layer_id].shape)\n",
    "            \n",
    "            AUROC[layer_id] = self.auroc(self.pred[layer_id], self.target[layer_id])\n",
    "            #accuracy[layer_id] = ((test_dists[layer_id] > self.thresholds[layer_id]).sum() / len(test_dists[layer_id]))\n",
    "                \n",
    "        return AUROC\n",
    "    \n",
    "    \n",
    "    \n",
    "    @torch.no_grad()        \n",
    "    def testset_correlation(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        corr_coeffs = {layer_id: SpearmanCorrCoef() for layer_id in self.layer_ids}\n",
    "        for batch in test_loader:\n",
    "            input_ = batch['input']\n",
    "            target = batch['target']\n",
    "            if self.net_out == 'calgary':\n",
    "                dist_volume = []\n",
    "                net_out_volume = []\n",
    "                for input_chunk in input_:\n",
    "                    dist, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                    dist_volume.append(dist.copy())\n",
    "                    net_out_volume.append(net_out.cpu())\n",
    "                dist = default_collate(dist_volume)            \n",
    "                net_out = torch.cat(net_out_volume, dim=0)\n",
    "            \n",
    "            if self.net_out == 'mms':\n",
    "                target[target == -1] = 0\n",
    "                # convert to one-hot encoding\n",
    "                target = F.one_hot(target.long(), num_classes=4).squeeze(1).permute(0,3,1,2)\n",
    "                dist, net_out = self.forward(input_.to(self.device))            \n",
    "            loss = self.criterion(net_out.cpu(), target)\n",
    "\n",
    "            loss = loss.mean().float().cpu()\n",
    "            for layer_id in self.layer_ids:\n",
    "                corr_coeffs[layer_id].update(dist[layer_id].cpu().mean(), 1-loss)\n",
    "\n",
    "        return corr_coeffs\n",
    "\n",
    "\n",
    "    @torch.no_grad()  \n",
    "    def forward(self, input_: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        handles = {}\n",
    "        for layer_id in self.layer_ids:\n",
    "            layer = self.model.get_submodule(layer_id)\n",
    "            hook  = self._get_hook_fn(layer_id, mode='single')\n",
    "            handles[layer_id] = layer.register_forward_pre_hook(hook)\n",
    "        \n",
    "        net_out = self.model(input_)\n",
    "        \n",
    "        for layer_id in self.layer_ids:\n",
    "            latent_centered = self.dist[layer_id].view(self.dist[layer_id].shape[0], 1, -1) - \\\n",
    "                self.mu[layer_id].unsqueeze(0)\n",
    "            self.dist[layer_id] = latent_centered @ self.sigma_inv[layer_id] @ \\\n",
    "                latent_centered.permute(0,2,1)\n",
    "            handles[layer_id].remove()\n",
    "            \n",
    "        return self.dist, net_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a029e7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lennartz/anaconda3/envs/default/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "detector = PoolingMahalabonisDetector(\n",
    "        model=unet, \n",
    "        layer_ids=['up3'], \n",
    "        train_loader=loader['train'], \n",
    "        valid_loader=loader['val'],\n",
    "        net_out='mms',\n",
    "        criterion=DiceScoreMMS(),\n",
    "        device='cuda:0'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a9537448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2580]) torch.Size([2580])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'up3': tensor(0.9740)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.testset_ood_detection(loader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "607e71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEMahalabonisDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    Evaluation class for OOD and ESCE tasks based on AEs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module, \n",
    "        layer_ids: dict, \n",
    "        train_loader: DataLoader, \n",
    "        valid_loader: DataLoader,\n",
    "        net_out: str,\n",
    "        criterion: nn.Module = DiceScoreCalgary(),\n",
    "        device: str = 'cuda:0'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device       = device\n",
    "        self.model        = model.to(device)\n",
    "        self.layer_ids    = layer_ids\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.net_out      = net_out\n",
    "        self.criterion    = criterion\n",
    "        self.auroc        = AUROC(task = 'binary')\n",
    "        \n",
    "        # Remove training hooks if necessary\n",
    "        self.model.remove_all_hooks()\n",
    "    \n",
    "        # Put model in evaluation state\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        self.model.freeze_seg_model()\n",
    "        \n",
    "        # Init score dict for each layer:\n",
    "        self.latents = {layer_id: [] for layer_id in self.layer_ids}\n",
    "        self.mu = {layer_id: None for layer_id in self.layer_ids}\n",
    "        self.sigma_inv = {layer_id: None for layer_id in self.layer_ids}\n",
    "        self.dist = {layer_id : 0 for layer_id in self.layer_ids}\n",
    "        \n",
    "        self._get_latents()\n",
    "        self._fit_gaussian_to_latents()\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _get_hook_fn(self, layer_id: str, mode: str = 'collect') -> Callable:\n",
    "        \n",
    "        def hook_fn(module: nn.Module, x: Tuple[Tensor]):\n",
    "            #print(x[0].shape)\n",
    "            #latent = self.model.transformations[layer_id](x[0])\n",
    "            latent = self.model.transformations[layer_id].get_latent(x[0]).detach().cpu()\n",
    "            #latent = torch.cat([mu, log_var], dim=-1).detach().cpu()\n",
    "            if mode == 'collect':\n",
    "                self.latents[layer_id].append(latent)\n",
    "            elif mode == 'single':\n",
    "                self.dist[layer_id] = latent.to(self.device)\n",
    "\n",
    "        return hook_fn\n",
    "        \n",
    "        \n",
    "    @torch.no_grad()        \n",
    "    def _get_latents(self) -> None:\n",
    "        handles = {}\n",
    "        for layer_id in self.layer_ids:\n",
    "            layer = self.model.seg_model.get_submodule(layer_id)\n",
    "            hook  = self._get_hook_fn(layer_id, mode='collect')\n",
    "            handles[layer_id] = layer.register_forward_pre_hook(hook)\n",
    "\n",
    "        for batch in self.train_loader:\n",
    "            input_ = batch['input'].to(self.device)\n",
    "            _ = self.model.seg_model(input_)\n",
    "                \n",
    "        for layer_id in handles:\n",
    "            self.latents[layer_id] = torch.cat(self.latents[layer_id], dim=0)\n",
    "            handles[layer_id].remove()\n",
    "        \n",
    "        \n",
    "    @torch.no_grad()         \n",
    "    def _fit_gaussian_to_latents(self) -> None:\n",
    "        for layer_id in self.layer_ids:\n",
    "            self.mu[layer_id] = self.latents[layer_id].mean(0, keepdims=True).to(self.device)\n",
    "            latents_centered = (self.latents[layer_id] - self.mu[layer_id].cpu()).detach().numpy()\n",
    "            sigma = torch.from_numpy(LedoitWolf().fit(latents_centered).covariance_)\n",
    "            self.sigma_inv[layer_id] = torch.linalg.inv(sigma).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def testset_ood_detection(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        \n",
    "        self.pred = {}\n",
    "        self.target = {}\n",
    "        if not hasattr(self, 'valid_dists'):\n",
    "            valid_dists = {layer_id : [] for layer_id in self.layer_ids}\n",
    "            for batch in self.valid_loader:\n",
    "                input_ = batch['input']\n",
    "                #print(input_.shape)\n",
    "                if self.net_out == 'calgary':\n",
    "                    dist_volume = []\n",
    "                    for input_chunk in input_:\n",
    "                        dist, _ = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                        dist_volume.append(dist.copy())\n",
    "                    dist = default_collate(dist_volume)\n",
    "                elif self.net_out == 'mms': \n",
    "                    dist, _ = self.forward(input_.to(self.device))\n",
    "                for layer_id in self.layer_ids:\n",
    "                    if self.net_out == 'calgary':\n",
    "                        valid_dists[layer_id].append(dist[layer_id].mean())\n",
    "                    elif self.net_out == 'mms':\n",
    "                        valid_dists[layer_id].append(dist[layer_id])\n",
    "            self.valid_dists = valid_dists\n",
    "            self.valid_labels = {layer_id: torch.zeros(len(self.valid_dists[layer_id]), dtype=torch.uint8) \n",
    "                                 for layer_id in self.layer_ids}\n",
    "        #print(len(self.valid_dists['up3']), len(self.valid_labels['up3']))\n",
    "            \n",
    "#             self.thresholds = {layer_id : 0 for layer_id in self.layer_ids}\n",
    "#             for layer_id in self.layer_ids:\n",
    "#                 if self.net_out == 'calgary':\n",
    "#                     valid_dists[layer_id] = torch.tensor(valid_dists[layer_id]).cpu()\n",
    "#                 elif self.net_out == 'mms':\n",
    "#                     valid_dists[layer_id] = torch.cat(valid_dists[layer_id], dim=0).cpu()\n",
    "#                 self.thresholds[layer_id] = torch.sort(valid_dists[layer_id])[0][len(valid_dists[layer_id]) - (len(valid_dists[layer_id]) // 20) - 1]\n",
    "                \n",
    "                    \n",
    "        test_dists = {layer_id : [] for layer_id in self.layer_ids}\n",
    "        for batch in test_loader:\n",
    "            input_ = batch['input']\n",
    "            if self.net_out == 'calgary':\n",
    "                dist_volume = []\n",
    "                for input_chunk in input_:\n",
    "                    dist, _ = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                    dist_volume.append(dist.copy())\n",
    "                dist = default_collate(dist_volume)\n",
    "            elif self.net_out == 'mms': \n",
    "                dist, _ = self.forward(input_.to(self.device))\n",
    "            for layer_id in self.layer_ids:\n",
    "                if self.net_out == 'calgary':\n",
    "                    test_dists[layer_id].append(dist[layer_id].mean())\n",
    "                elif self.net_out == 'mms':    \n",
    "                    test_dists[layer_id].append(dist[layer_id])\n",
    "        \n",
    "        self.test_dists = test_dists\n",
    "        self.test_labels = {layer_id: torch.ones(len(self.test_dists[layer_id]), dtype=torch.uint8) \n",
    "                             for layer_id in self.layer_ids}\n",
    "            \n",
    "            \n",
    "        AUROC = {layer_id : 0 for layer_id in self.layer_ids}\n",
    "        for layer_id in self.layer_ids:\n",
    "            if self.net_out == 'calgary':\n",
    "                self.valid_dists[layer_id] = torch.tensor(self.valid_dists[layer_id]).cpu()\n",
    "                self.test_dists[layer_id]  = torch.tensor(self.test_dists[layer_id]).cpu()\n",
    "            elif self.net_out == 'mms':\n",
    "                self.valid_dists[layer_id] = torch.cat(self.valid_dists[layer_id], dim=0).cpu()\n",
    "                self.test_dists[layer_id]  = torch.cat(self.test_dists[layer_id], dim=0).cpu()\n",
    "            self.pred[layer_id]   = torch.cat([self.valid_dists[layer_id], self.test_dists[layer_id]]).squeeze()\n",
    "            self.target[layer_id] = torch.cat([self.valid_labels[layer_id], self.test_labels[layer_id]]).squeeze()\n",
    "            #print(self.pred[layer_id].shape, self.target[layer_id].shape)\n",
    "            AUROC[layer_id] = self.auroc(self.pred[layer_id], self.target[layer_id])\n",
    "            #accuracy[layer_id] = ((test_dists[layer_id] > self.thresholds[layer_id]).sum() / len(test_dists[layer_id]))\n",
    "                \n",
    "        return AUROC\n",
    "    \n",
    "    \n",
    "    @torch.no_grad()        \n",
    "    def testset_correlation(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        corr_coeffs = {layer_id: SpearmanCorrCoef() for layer_id in self.layer_ids}\n",
    "        for batch in test_loader:\n",
    "            input_ = batch['input']\n",
    "            target = batch['target']\n",
    "            if self.net_out == 'calgary':\n",
    "                dist_volume = []\n",
    "                net_out_volume = []\n",
    "                for input_chunk in input_:\n",
    "                    dist, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                    dist_volume.append(dist.copy())\n",
    "                    net_out_volume.append(net_out.cpu())\n",
    "                dist = default_collate(dist_volume)            \n",
    "                net_out = torch.cat(net_out_volume, dim=0)\n",
    "            \n",
    "            elif self.net_out == 'mms': \n",
    "                target[target == -1] = 0\n",
    "                # convert to one-hot encoding\n",
    "                target = F.one_hot(target.long(), num_classes=4).squeeze(1).permute(0,3,1,2)\n",
    "                dist, net_out = self.forward(input_.to(self.device))            \n",
    "            loss = self.criterion(net_out.cpu(), target)\n",
    "            loss = loss.mean().float().cpu()\n",
    "            for layer_id in self.layer_ids:\n",
    "                corr_coeffs[layer_id].update(dist[layer_id].cpu().mean(), 1-loss)\n",
    "\n",
    "        return corr_coeffs\n",
    "\n",
    "\n",
    "    @torch.no_grad()  \n",
    "    def forward(self, input_: torch.Tensor) -> Union[dict, torch.Tensor]:\n",
    "        \n",
    "        handles = {}\n",
    "        for layer_id in self.layer_ids:\n",
    "            layer = self.model.seg_model.get_submodule(layer_id)\n",
    "            hook  = self._get_hook_fn(layer_id, mode='single')\n",
    "            handles[layer_id] = layer.register_forward_pre_hook(hook)\n",
    "            \n",
    "        net_out = self.model.seg_model(input_)\n",
    "        \n",
    "        for layer_id in self.layer_ids:\n",
    "            latent_centered = self.dist[layer_id].view(self.dist[layer_id].shape[0], 1, -1) - self.mu[layer_id].unsqueeze(0)\n",
    "            self.dist[layer_id] = latent_centered @ self.sigma_inv[layer_id] @ latent_centered.permute(0,2,1)\n",
    "            handles[layer_id].remove()\n",
    "            \n",
    "        return self.dist, net_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "062ca500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lennartz/anaconda3/envs/default/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "detector = AEMahalabonisDetector(\n",
    "        model=model, \n",
    "        layer_ids=['up3'], \n",
    "        train_loader=loader['train'], \n",
    "        valid_loader=loader['val'],\n",
    "        net_out='mms',\n",
    "        criterion=DiceScoreMMS(),\n",
    "        device='cuda:0'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "36dcb347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2580]) torch.Size([2580])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'up3': tensor(0.7612)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.testset_ood_detection(loader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43ae7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanDistSamplesDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    Evaluation class for OOD and ESCE tasks based on VAEs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module, \n",
    "        n_samples: int,\n",
    "        net_out: str,\n",
    "        valid_loader: DataLoader,\n",
    "        criterion: nn.Module, # e.g. DiceScoreCalgary()\n",
    "        device: str = 'cuda:0',\n",
    "        method: str = 'vae'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.net_out  = net_out\n",
    "        # Remove trainiung hooks, add evaluation hooks\n",
    "        self.model.remove_all_hooks()        \n",
    "        self.model.hook_transformations(self.model.transformations,\n",
    "                                        n_samples=n_samples)\n",
    "        \n",
    "        self.model.eval()\n",
    "        self.model.freeze_seg_model()\n",
    "        \n",
    "        self.valid_loader = valid_loader\n",
    "        self.criterion = criterion\n",
    "        self.auroc = AUROC(task = 'binary')\n",
    "        self.umap_generator = UMapGenerator(method=method,\n",
    "                                            net_out=net_out)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def testset_ood_detection(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        if not hasattr(self, 'threshold'):\n",
    "            valid_dists = []\n",
    "            for batch in self.valid_loader:\n",
    "                input_ = batch['input'].to(0)\n",
    "                \n",
    "                if self.net_out == 'calgary':\n",
    "                    net_out_volume = []\n",
    "                    umap_volume  = []\n",
    "\n",
    "                    for input_chunk in input_:\n",
    "                        umap, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                        net_out_volume.append(net_out[:1].detach().cpu())\n",
    "                        umap_volume.append(umap)\n",
    "\n",
    "                    net_out = torch.cat(net_out_volume, dim=0)\n",
    "                    umap = torch.cat(umap_volume, dim=0)\n",
    "                    \n",
    "                if self.net_out == 'mms':\n",
    "                    umap, net_out = self.forward(input_.to(self.device))\n",
    "                score = torch.norm(umap).cpu()\n",
    "                valid_dists.append(score)\n",
    "                \n",
    "            self.valid_dists = torch.tensor(valid_dists)\n",
    "            self.valid_labels = torch.zeros(len(self.valid_dists), dtype=torch.uint8)\n",
    "        \n",
    "        test_dists = []\n",
    "        for batch in test_loader:\n",
    "            input_ = batch['input']\n",
    "\n",
    "            if self.net_out == 'calgary':\n",
    "                net_out_volume = []\n",
    "                umap_volume  = []\n",
    "\n",
    "                for input_chunk in input_:\n",
    "                    umap, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                    net_out_volume.append(net_out[:1].detach().cpu())\n",
    "                    umap_volume.append(umap)\n",
    "\n",
    "                net_out = torch.cat(net_out_volume, dim=0)\n",
    "                umap = torch.cat(umap_volume, dim=0)\n",
    "\n",
    "            if self.net_out == 'mms':\n",
    "                umap, net_out = self.forward(input_.to(self.device))\n",
    "\n",
    "            score = torch.norm(umap).cpu()\n",
    "            test_dists.append(score)\n",
    "        self.test_dists = torch.tensor(test_dists).cpu()\n",
    "        self.test_labels = torch.ones(len(self.test_dists), dtype=torch.uint8)\n",
    "        \n",
    "        self.pred =  torch.cat([self.valid_dists, self.test_dists]).squeeze()\n",
    "        self.target = torch.cat([self.valid_labels, self.test_labels]).squeeze()\n",
    "        print(self.pred.shape, self.target.shape)\n",
    "        AUROC = self.auroc(self.pred, self.target)\n",
    "        \n",
    "        return AUROC    \n",
    "        \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def testset_correlation(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        corr_coeff = SpearmanCorrCoef()\n",
    "        losses = []\n",
    "        for batch in test_loader:\n",
    "            input_ = batch['input']\n",
    "            target = batch['target']\n",
    "            \n",
    "            if self.net_out == 'calgary':\n",
    "                net_out_volume = []\n",
    "                umap_volume  = []\n",
    "\n",
    "                for input_chunk in input_:\n",
    "                    umap, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                    net_out_volume.append(net_out[:1].detach().cpu())\n",
    "                    umap_volume.append(umap)\n",
    "                    \n",
    "                net_out = torch.cat(net_out_volume, dim=0)\n",
    "                umap = torch.cat(umap_volume, dim=0)\n",
    "            \n",
    "            if self.net_out == 'mms':\n",
    "                target[target == -1] = 0\n",
    "                # convert to one-hot encoding\n",
    "                target = F.one_hot(target.long(), num_classes=4).squeeze(1).permute(0,3,1,2)\n",
    "                umap, net_out = self.forward(input_.to(self.device))\n",
    "            \n",
    "            \n",
    "            loss = self.criterion(net_out, target)\n",
    "            \n",
    "            loss = loss.mean().float()\n",
    "                    \n",
    "            score = torch.norm(umap)\n",
    "            losses.append(1-loss.view(1))\n",
    "            corr_coeff.update(score.cpu(), 1-loss)\n",
    "            \n",
    "        return corr_coeff\n",
    "\n",
    "    \n",
    "    @torch.no_grad()  \n",
    "    def forward(self, input_: torch.Tensor) -> torch.Tensor:\n",
    "        net_out = self.model(input_).cpu()\n",
    "        umap    = self.umap_generator(net_out).cpu()\n",
    "        return umap, net_out[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6bf37b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MeanDistSamplesDetector(\n",
    "        model=model, \n",
    "        n_samples=1,\n",
    "        net_out='mms',\n",
    "        valid_loader=loader['val'],\n",
    "        criterion=DiceScoreMMS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "905aff31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2580]) torch.Size([2580])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4271)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.testset_ood_detection(loader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aa3fc0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropyDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    Evaluation class for OOD and ESCE tasks based on AEs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module, \n",
    "        net_out: str,\n",
    "        valid_loader: DataLoader,\n",
    "        criterion: nn.Module,\n",
    "        device: str = 'cuda:0'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net_out = net_out\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        # Remove trainiung hooks, add evaluation hooks\n",
    "        # self.model.remove_all_hooks()        \n",
    "        \n",
    "        self.valid_loader = valid_loader\n",
    "        self.criterion = criterion\n",
    "        self.auroc = AUROC(task = 'binary')\n",
    "        self.umap_generator = UMapGenerator(method='probs',\n",
    "                                            net_out=net_out)\n",
    "        \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def testset_ood_detection(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        if not hasattr(self, 'valid_dists'):\n",
    "            valid_dists = []\n",
    "            for batch in self.valid_loader:\n",
    "                input_ = batch['input'].to(0)\n",
    "                \n",
    "                if self.net_out == 'calgary':\n",
    "                    net_out_volume = []\n",
    "                    umap_volume  = []\n",
    "\n",
    "                    for input_chunk in input_:\n",
    "                        umap, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                        net_out_volume.append(net_out.detach().cpu())\n",
    "                        umap_volume.append(umap)\n",
    "\n",
    "                    net_out = torch.cat(net_out_volume, dim=0)\n",
    "                    umap = torch.cat(umap_volume, dim=0)\n",
    "                    \n",
    "                if self.net_out == 'mms':\n",
    "                    umap, net_out = self.forward(input_.to(self.device))\n",
    "                score = torch.norm(umap).cpu()\n",
    "                valid_dists.append(score)\n",
    "                \n",
    "            self.valid_dists = torch.tensor(valid_dists)\n",
    "            self.valid_labels = torch.zeros(len(self.valid_dists), dtype=torch.uint8)\n",
    "        \n",
    "        test_dists = []\n",
    "        for batch in test_loader:\n",
    "            input_ = batch['input']\n",
    "\n",
    "            if self.net_out == 'calgary':\n",
    "                net_out_volume = []\n",
    "                umap_volume  = []\n",
    "\n",
    "                for input_chunk in input_:\n",
    "                    umap, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                    net_out_volume.append(net_out.detach().cpu())\n",
    "                    umap_volume.append(umap)\n",
    "\n",
    "                net_out = torch.cat(net_out_volume, dim=0)\n",
    "                umap = torch.cat(umap_volume, dim=0)\n",
    "\n",
    "            if self.net_out == 'mms':\n",
    "                umap, net_out = self.forward(input_.to(self.device))\n",
    "\n",
    "            score = torch.norm(umap).cpu()\n",
    "            test_dists.append(score)\n",
    "        self.test_dists = torch.tensor(test_dists).cpu()\n",
    "        self.test_labels = torch.ones(len(self.test_dists), dtype=torch.uint8)\n",
    "        \n",
    "        self.pred =  torch.cat([self.valid_dists, self.test_dists]).squeeze()\n",
    "        self.target = torch.cat([self.valid_labels, self.test_labels]).squeeze()\n",
    "        print(self.pred.shape, self.target.shape)\n",
    "        AUROC = self.auroc(self.pred, self.target)\n",
    "        \n",
    "        return AUROC     \n",
    "        \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def testset_correlation(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        corr_coeff = SpearmanCorrCoef()\n",
    "        losses = []\n",
    "        for batch in test_loader:\n",
    "            input_ = batch['input'].to(0)\n",
    "            target = batch['target']\n",
    "            \n",
    "            if self.net_out == 'calgary':\n",
    "                net_out_volume = []\n",
    "                umap_volume  = []\n",
    "\n",
    "                for input_chunk in input_:\n",
    "                    umap, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                    net_out_volume.append(net_out[:1].detach().cpu())\n",
    "                    umap_volume.append(umap)\n",
    "                    \n",
    "                net_out = torch.cat(net_out_volume, dim=0)\n",
    "                umap = torch.cat(umap_volume, dim=0)\n",
    "            \n",
    "            if self.net_out == 'mms':\n",
    "                target[target == -1] = 0\n",
    "                # convert to one-hot encoding\n",
    "                target = F.one_hot(target.long(), num_classes=4).squeeze(1).permute(0,3,1,2)\n",
    "                umap, net_out = self.forward(input_.to(self.device))\n",
    "            \n",
    "            \n",
    "            loss = self.criterion(net_out.cpu(), target.cpu())\n",
    "            loss = loss.mean().cpu().float()\n",
    "                    \n",
    "            score = torch.norm(umap)\n",
    "            losses.append(1-loss.view(1))\n",
    "            corr_coeff.update(score.cpu(), 1-loss)\n",
    "            \n",
    "        return corr_coeff\n",
    "\n",
    "    \n",
    "    @torch.no_grad()  \n",
    "    def forward(self, input_: torch.Tensor) -> torch.Tensor:\n",
    "        self.model.eval()\n",
    "        net_out = self.model(input_)\n",
    "        umap = self.umap_generator(net_out)\n",
    "        #score = torch.linalg.norm(umap, dim=(-2, -1))\n",
    "        return umap, net_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "65bf9340",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = EntropyDetector(\n",
    "        model=unet, \n",
    "        net_out='mms',\n",
    "        valid_loader=loader['val'],\n",
    "        criterion=DiceScoreMMS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f802f870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2580]) torch.Size([2580])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7241)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.testset_ood_detection(loader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "eb34bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleEntropyDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    Evaluation class for OOD and ESCE tasks based on AEs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module, \n",
    "        net_out: str,\n",
    "        valid_loader: DataLoader,\n",
    "        criterion: nn.Module,\n",
    "        device: str = 'cuda:0'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net_out = net_out\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        torch.manual_seed(42)\n",
    "        self.ensemble_compositions = torch.cat([torch.arange(10).view(10,1), \n",
    "                                                torch.randint(0, 9, (10, 4))],\n",
    "                                               dim=1)\n",
    "        # Remove trainiung hooks, add evaluation hooks\n",
    "        # self.model.remove_all_hooks()        \n",
    "        \n",
    "        self.valid_loader = valid_loader\n",
    "        self.criterion = criterion\n",
    "        self.auroc = AUROC(task = 'binary')\n",
    "        self.umap_generator = UMapGenerator(method='probs',\n",
    "                                            net_out=net_out)\n",
    "        \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def testset_ood_detection(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        \n",
    "        if not hasattr(self, 'valid_dists'):\n",
    "            valid_dists = []\n",
    "            for batch in self.valid_loader:\n",
    "                input_ = batch['input'].to(0)\n",
    "                net_out = self.forward(input_.to(self.device))\n",
    "                umap = self.umap_generator(net_out)\n",
    "                scores = (umap**2).mean(dim=(1,2)).cpu()\n",
    "                valid_dists.append(scores)\n",
    "            self.valid_dists = torch.stack(valid_dists, dim=0)\n",
    "            self.valid_labels = torch.zeros(len(self.valid_dists), dtype=torch.uint8)\n",
    "            \n",
    "        test_dists = []\n",
    "        for batch in test_loader:\n",
    "            input_ = batch['input']\n",
    "            net_out = self.forward(input_.to(self.device))\n",
    "            umap = self.umap_generator(net_out)\n",
    "            scores = torch.sqrt((umap**2).sum(dim=(1,2))).cpu()\n",
    "            test_dists.append(scores)\n",
    "            \n",
    "        self.test_dists = torch.stack(test_dists, dim=0).cpu()\n",
    "        self.test_labels = torch.ones(len(self.test_dists), dtype=torch.uint8)\n",
    "        \n",
    "        \n",
    "        self.pred = torch.cat([self.valid_dists, self.test_dists], dim=0).T\n",
    "        self.target = torch.cat([self.valid_labels, self.test_labels])\n",
    "        \n",
    "        print(ensemble_compositions[0], self.pred[ensemble_compositions[0]].mean(0).shape, self.target.shape)\n",
    "        \n",
    "        AUROC = [self.auroc(self.pred[ensemble_compositions[i]].mean(0), self.target) \n",
    "                 for i in range(10)]\n",
    "        \n",
    "        return AUROC\n",
    "        #accuracy = (test_dists > self.thresholds).sum(dim=0) / len(test_dists)\n",
    "        \n",
    "        #return accuracy       \n",
    "        \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def testset_correlation(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        corr_coeffs = [SpearmanCorrCoef() for _ in range(10)]\n",
    "        losses = []\n",
    "        for batch in tqdm(test_loader):\n",
    "            input_ = batch['input'].to(0)\n",
    "            target = batch['target']\n",
    "            \n",
    "            if self.net_out == 'calgary':\n",
    "                net_out_volume = []\n",
    "\n",
    "                for input_chunk in input_:\n",
    "                    net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                    net_out_volume.append(net_out.detach().cpu())\n",
    "                net_out = torch.stack(net_out_volume, dim=0)\n",
    "\n",
    "            if self.net_out == 'mms':\n",
    "                target[target == -1] = 0\n",
    "                # convert to one-hot encoding\n",
    "                target = F.one_hot(target.long(), num_classes=4).squeeze(1).permute(0,3,1,2)\n",
    "                net_out = self.forward(input_.to(self.device))\n",
    "            \n",
    "            \n",
    "            for i, corr_coeff in enumerate(corr_coeffs):\n",
    "                ensemble_idxs = self.ensemble_compositions[i]\n",
    "                \n",
    "                if self.net_out == 'calgary':\n",
    "                    loss = self.criterion(net_out[:, i:i+1].cpu(), target.cpu())\n",
    "                    umap_volume  = []\n",
    "                    for slc in net_out:\n",
    "                        umap = self.umap_generator(slc[ensemble_idxs].mean(0, keepdim=True))\n",
    "                        umap_volume.append(umap)\n",
    "                    umap = torch.cat(umap_volume, dim=0)\n",
    "                \n",
    "                if self.net_out == 'mms':\n",
    "                    #loss = self.criterion(net_out[i:i+1].cpu(), target.cpu())\n",
    "                    loss = self.criterion(net_out[ensemble_idxs].mean(dim=0, keepdim=True).cpu(), target.cpu())\n",
    "                    umap = self.umap_generator(net_out[ensemble_idxs].mean(0, keepdim=True))\n",
    "                    \n",
    "                score = torch.norm(umap).cpu()    \n",
    "                loss = loss.mean().cpu().float()\n",
    "                corr_coeff.update(score, 1-loss)\n",
    "            \n",
    "        return corr_coeffs\n",
    "\n",
    "    \n",
    "    @torch.no_grad()  \n",
    "    def forward(self, input_: torch.Tensor) -> torch.Tensor:\n",
    "        self.model.eval()\n",
    "        net_out = self.model(input_)\n",
    "        return net_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b2641021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - get indices for unet ensemble\n",
    "torch.manual_seed(42)\n",
    "ensemble_compositions = torch.cat([torch.arange(10).view(10,1), \n",
    "                                    torch.randint(0, 9, (10, 4))],\n",
    "                                   dim=1)\n",
    "\n",
    "# - path\n",
    "root = '../../'\n",
    "# U-Nets\n",
    "middle = 'unet8_' #c\n",
    "pre = 'acdc'   #c\n",
    "unet_names = [f'{pre}_{middle}{i}' for i in range(10)] #TODO\n",
    "unets = []\n",
    "for name in unet_names:\n",
    "    model_path = f'{root}pre-trained-tmp/trained_UNets/{name}_best.pt' #c\n",
    "    state_dict = torch.load(model_path)['model_state_dict']\n",
    "    n_chans_out = 4 #c\n",
    "    unet = UNet2D(n_chans_in=1, \n",
    "                  n_chans_out=n_chans_out, \n",
    "                  n_filters_init=8, \n",
    "                  dropout=False)\n",
    "    unet.load_state_dict(state_dict)\n",
    "    unet.cuda()\n",
    "    unets.append(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2b0c343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = UNetEnsemble(unets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9689b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = EnsembleEntropyDetector(\n",
    "        model=ensemble, \n",
    "        net_out='mms',\n",
    "        valid_loader=loader['val'],\n",
    "        criterion=DiceScoreMMS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "370bee05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 6, 5, 7, 4]) torch.Size([100]) torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(1.),\n",
       " tensor(1.),\n",
       " tensor(1.),\n",
       " tensor(1.),\n",
       " tensor(1.),\n",
       " tensor(1.),\n",
       " tensor(1.),\n",
       " tensor(1.),\n",
       " tensor(1.),\n",
       " tensor(1.)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.testset_ood_detection(loader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009f6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e258a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f276ca0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5914073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = AUROC(task = 'binary', num_classes=2, average=None)\n",
    "pred = torch.rand((10,10))\n",
    "target = torch.ones((10,10), dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "37236dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a364730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
