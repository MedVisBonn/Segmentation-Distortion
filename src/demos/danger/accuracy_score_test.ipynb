{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d2afb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "import collections\n",
    "from random import sample, seed\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import Dataset, DataLoader, default_collate\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append('..')\n",
    "from dataset import CalgaryCampinasDataset, ACDCDataset, MNMDataset\n",
    "from model.unet import UNet2D, UNetEnsemble\n",
    "from model.ae import AE\n",
    "from model.dae import resDAE, AugResDAE\n",
    "from model.wrapper import Frankenstein\n",
    "from losses import (\n",
    "    DiceScoreCalgary, \n",
    "    DiceScoreMMS, \n",
    "    SurfaceDiceCalgary,\n",
    "    AccMMS\n",
    ")\n",
    "from utils import volume_collate\n",
    "from eval.slice_wise import (\n",
    "    PoolingMahalabonisDetector, \n",
    "    AEMahalabonisDetector, \n",
    "    MeanDistSamplesDetector, \n",
    "    EntropyDetector, \n",
    "    EnsembleEntropyDetector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce1c1954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "ROOT = '../../'\n",
    "SEED = 42\n",
    "debug=False\n",
    "net_out='mms'\n",
    "method='single'\n",
    "task='corr'\n",
    "scanner='A'\n",
    "n_unets=1\n",
    "post='localAug_multiImgSingleView_res_balanced_same'\n",
    "\n",
    "data = 'data/mnm/'\n",
    "data_path = ROOT + data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a292e456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n",
      "loading all case properties\n",
      "loading dataset\n",
      "loading all case properties\n",
      "loading dataset\n",
      "loading all case properties\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_set = ACDCDataset(data='train', \n",
    "                        debug=debug)\n",
    "\n",
    "train_loader = DataLoader(train_set, \n",
    "                          batch_size=32, \n",
    "                          shuffle=False,\n",
    "                          drop_last=False,\n",
    "                          num_workers=10)\n",
    "\n",
    "valid_set = ACDCDataset(data='val', \n",
    "                        debug=debug)\n",
    "\n",
    "valid_loader = DataLoader(valid_set, \n",
    "                          batch_size=1, \n",
    "                          shuffle=False, \n",
    "                          drop_last=False, \n",
    "                          num_workers=10)\n",
    "\n",
    "if scanner != 'val':\n",
    "    test_set = MNMDataset(vendor=scanner, \n",
    "                          debug=debug)\n",
    "else:\n",
    "    test_set = ACDCDataset(data=scanner, \n",
    "                           debug=debug)\n",
    "\n",
    "test_loader = DataLoader(test_set, \n",
    "                         batch_size=1, \n",
    "                         shuffle=False, \n",
    "                         drop_last=False,\n",
    "                         num_workers=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c66fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Nets\n",
    "middle = 'unet' if net_out == 'calgary' else 'unet8_'\n",
    "pre = 'calgary' if net_out == 'calgary' else 'acdc'\n",
    "unet_names = [f'{pre}_{middle}{i}' for i in range(n_unets)] #TODO\n",
    "unets = []\n",
    "for name in unet_names:\n",
    "    model_path = f'{ROOT}pre-trained-tmp/trained_UNets/{name}_best.pt'\n",
    "    state_dict = torch.load(model_path)['model_state_dict']\n",
    "    n_chans_out = 1 if net_out == 'calgary' else 4\n",
    "    unet = UNet2D(n_chans_in=1, \n",
    "                  n_chans_out=n_chans_out, \n",
    "                  n_filters_init=8, \n",
    "                  dropout=False)\n",
    "    unet.load_state_dict(state_dict)\n",
    "    unets.append(unet)\n",
    "\n",
    "metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "392feadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Dict, List, Callable, Tuple, Union, List\n",
    "\n",
    "import torch #\n",
    "from torch import Tensor, nn #\n",
    "from torch.utils.data import Dataset, DataLoader, default_collate\n",
    "import torch.nn.functional as F\n",
    "from sklearn.cluster import KMeans #\n",
    "from sklearn.metrics import pairwise_distances_argmin_min #\n",
    "from sklearn.covariance import LedoitWolf #\n",
    "from scipy.stats import binned_statistic #\n",
    "from tqdm.auto import tqdm #\n",
    "from torchmetrics import (\n",
    "    SpearmanCorrCoef, \n",
    "    AUROC)\n",
    "from losses import DiceScoreCalgary, DiceScoreMMS #\n",
    "from utils import _activate_dropout, UMapGenerator\n",
    "\n",
    "\n",
    "class MeanDistSamplesDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    Evaluation class for OOD and ESCE tasks based on VAEs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module, \n",
    "        n_samples: int,\n",
    "        net_out: str,\n",
    "        valid_loader: DataLoader,\n",
    "        criterion: nn.Module, # e.g. DiceScoreCalgary()\n",
    "        device: str = 'cuda:0',\n",
    "        method: str = 'vae'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.net_out  = net_out\n",
    "        # Remove trainiung hooks, add evaluation hooks\n",
    "        self.model.remove_all_hooks()        \n",
    "        self.model.hook_inference_transformations(self.model.transformations,\n",
    "                                        n_samples=n_samples)\n",
    "        \n",
    "        self.model.eval()\n",
    "        self.model.freeze_seg_model()\n",
    "        \n",
    "        self.valid_loader = valid_loader\n",
    "        self.criterion = criterion\n",
    "        self.auroc = AUROC(task = 'binary')\n",
    "        self.umap_generator = UMapGenerator(method=method,\n",
    "                                            net_out=net_out)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def testset_ood_detection(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        if not hasattr(self, 'threshold'):\n",
    "            valid_dists = []\n",
    "            for batch in self.valid_loader:\n",
    "                input_ = batch['input'].to(0)\n",
    "                \n",
    "                if self.net_out == 'calgary':\n",
    "                    net_out_volume = []\n",
    "                    umap_volume  = []\n",
    "\n",
    "                    for input_chunk in input_:\n",
    "                        umap, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                        net_out_volume.append(net_out[:1].detach().cpu())\n",
    "                        umap_volume.append(umap)\n",
    "\n",
    "                    net_out = torch.cat(net_out_volume, dim=0)\n",
    "                    umap = torch.cat(umap_volume, dim=0)\n",
    "                    \n",
    "                if self.net_out == 'mms':\n",
    "                    umap, net_out = self.forward(input_.to(self.device))\n",
    "                score = torch.norm(umap).cpu()\n",
    "                valid_dists.append(score)\n",
    "                \n",
    "            self.valid_dists = torch.tensor(valid_dists)\n",
    "            self.valid_labels = torch.zeros(len(self.valid_dists), dtype=torch.uint8)\n",
    "        \n",
    "        test_dists = []\n",
    "        for batch in test_loader:\n",
    "            input_ = batch['input']\n",
    "\n",
    "            if self.net_out == 'calgary':\n",
    "                net_out_volume = []\n",
    "                umap_volume  = []\n",
    "\n",
    "                for input_chunk in input_:\n",
    "                    umap, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                    net_out_volume.append(net_out[:1].detach().cpu())\n",
    "                    umap_volume.append(umap)\n",
    "\n",
    "                net_out = torch.cat(net_out_volume, dim=0)\n",
    "                umap = torch.cat(umap_volume, dim=0)\n",
    "\n",
    "            if self.net_out == 'mms':\n",
    "                umap, net_out = self.forward(input_.to(self.device))\n",
    "\n",
    "            score = torch.norm(umap).cpu()\n",
    "            test_dists.append(score)\n",
    "        self.test_dists = torch.tensor(test_dists).cpu()\n",
    "        self.test_labels = torch.ones(len(self.test_dists), dtype=torch.uint8)\n",
    "        \n",
    "        self.pred =  torch.cat([self.valid_dists, self.test_dists]).squeeze()\n",
    "        self.target = torch.cat([self.valid_labels, self.test_labels]).squeeze()\n",
    "        print(self.pred.shape, self.target.shape)\n",
    "        AUROC = self.auroc(self.pred, self.target)\n",
    "        \n",
    "        return AUROC    \n",
    "        \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def testset_correlation(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        corr_coeff = SpearmanCorrCoef()\n",
    "        losses = []\n",
    "        for batch in test_loader:\n",
    "            input_ = batch['input']\n",
    "            target = batch['target']\n",
    "            \n",
    "            if self.net_out == 'calgary':\n",
    "                net_out_volume = []\n",
    "                umap_volume  = []\n",
    "\n",
    "                for input_chunk in input_:\n",
    "                    umap, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                    net_out_volume.append(net_out[:1].detach().cpu())\n",
    "                    umap_volume.append(umap)\n",
    "                    \n",
    "                net_out = torch.cat(net_out_volume, dim=0)\n",
    "                umap = torch.cat(umap_volume, dim=0)\n",
    "            \n",
    "            if self.net_out == 'mms':\n",
    "                target[target == -1] = 0\n",
    "                # convert to one-hot encoding\n",
    "                target = F.one_hot(target.long(), num_classes=4).squeeze(1).permute(0,3,1,2)\n",
    "                #print(target.min(), target.max())\n",
    "                umap, net_out = self.forward(input_.to(self.device))\n",
    "            \n",
    "#             try:\n",
    "#                 print(net_out.shape, target.shape)\n",
    "            loss = self.criterion(net_out, torch.argmax(target, dim=1))\n",
    "#                 print(loss)\n",
    "#             except:\n",
    "#                 net_out = torch.rand(10, 4, 20, 20)\n",
    "#                 target = torch.argmax(\n",
    "#                     torch.tensor([1,0,0,0]).view(1, 4, 1, 1).repeat(10, 1, 20, 20),\n",
    "#                     dim=1\n",
    "#                 )\n",
    "#                 self.criterion(net_out, target)\n",
    "#                 print(target.min(), target.max())\n",
    "            \n",
    "            loss = loss.mean().float()\n",
    "            \n",
    "            score = torch.norm(umap)\n",
    "            #print(loss.shape, score.shape)\n",
    "            losses.append(1-loss.view(1))\n",
    "            corr_coeff.update(score.cpu().view(1,), 1-loss.view(1,))\n",
    "            \n",
    "        return corr_coeff\n",
    "\n",
    "    \n",
    "    @torch.no_grad()  \n",
    "    def forward(self, input_: torch.Tensor) -> torch.Tensor:\n",
    "        net_out = self.model(input_).cpu()\n",
    "        umap    = self.umap_generator(net_out).cpu()\n",
    "        return umap, net_out[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43a7c7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fcb0414aae4562bff6ac046021e29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method single, Unet 0 - mms\n"
     ]
    }
   ],
   "source": [
    "disabled_ids = ['shortcut0', 'shortcut1', 'shortcut2']\n",
    "DAEs = nn.ModuleDict({'up3': AugResDAE(in_channels = 64, \n",
    "                                    in_dim      = 32,\n",
    "                                    latent_dim  = 256 if net_out=='mms' else 64,\n",
    "                                    depth       = 3,\n",
    "                                    block_size  = 4)})\n",
    "\n",
    "\n",
    "for layer_id in disabled_ids:\n",
    "    DAEs[layer_id] = nn.Identity()\n",
    "\n",
    "for i, unet in enumerate(tqdm(unets)):\n",
    "    print(f\"Method {method}, Unet {i} - {net_out}\")\n",
    "\n",
    "    model = Frankenstein(seg_model=unet,\n",
    "                         transformations=DAEs,\n",
    "                         disabled_ids=disabled_ids,\n",
    "                         copy=True)\n",
    "    model_path = f'{ROOT}pre-trained-tmp/trained_AEs/acdc_AugResDAE{i}_{post}_best.pt'\n",
    "    #model_path = f'{ROOT}pre-trained-tmp/trained_AEs/{pre}_resDAE{i}_{post}_best.pt'\n",
    "    #model_path = f'{ROOT}pre-trained-tmp/trained_AEs/acdc_epinet_CE-only_prior-1_best.pt'\n",
    "    #model_path = f'{ROOT}pre-trained-tmp/trained_AEs/acdc_resDAE0_venus_best.pt'\n",
    "    state_dict = torch.load(model_path)['model_state_dict']\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    metrics.append({})\n",
    "    detector = MeanDistSamplesDetector(model=model,\n",
    "                                       n_samples=1,\n",
    "                                       valid_loader=valid_loader,\n",
    "                                       net_out=net_out,\n",
    "                                       method='mse',\n",
    "                                       criterion=AccMMS())\n",
    "    if task == 'ood' or task == 'both':\n",
    "        metrics[i]['ood'] = detector.testset_ood_detection(test_loader)\n",
    "    if task == 'corr' or task == 'both':\n",
    "        metrics[i]['corr'] = detector.testset_correlation(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81750b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4242)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[0]['corr'].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "957f2a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4281)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[0]['corr'].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0052be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e9af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = torchmetrics.Accuracy(\n",
    "    task='multiclass', \n",
    "    num_classes=4, \n",
    "    multidim_average='samplewise', \n",
    "    average='macro', \n",
    "    ignore_index=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f29513bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.rand(10, 4, 20, 20)\n",
    "tar = torch.argmax(\n",
    "    torch.tensor([1,0,0,0]).view(1, 4, 1, 1).repeat(10, 1, 20, 20),\n",
    "    dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a762d9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2450, 0.2300, 0.2425, 0.2325, 0.2500, 0.2275, 0.2625, 0.2350, 0.2450,\n",
       "        0.2625])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(inp, tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4cf5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
