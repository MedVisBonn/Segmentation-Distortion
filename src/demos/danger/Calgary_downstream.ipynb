{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f1c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0ff044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a84e7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "from typing import Iterable, Dict, List, Callable, Tuple, Union, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "import fiftyone as fo\n",
    "import shutil\n",
    "from torchmetrics import Dice\n",
    "\n",
    "sys.path.append('../../')\n",
    "from dataset import CalgaryCampinasDataset\n",
    "from model.unet import UNet2D\n",
    "from model.ae import AE\n",
    "from model.dae import resDAE, AugResDAE\n",
    "from model.wrapper import Frankenstein, ModelAdapter\n",
    "from losses import DiceScoreCalgary, SurfaceDiceCalgary\n",
    "from utils import  epoch_average, UMapGenerator, volume_collate\n",
    "from trainer.unet_trainer import UNetTrainerCalgary\n",
    "from data_utils import get_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f07ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config\n",
    "root = '../../../'\n",
    "data_dir = 'data/conp-dataset/projects/calgary-campinas/CC359/Reconstructed/'\n",
    "data_path = root + data_dir\n",
    "debug = False\n",
    "augment = False\n",
    "site = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e57666f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CalgaryCampinasDataset(\n",
    "    data_path=data_path, \n",
    "    site=6,\n",
    "    split='train',\n",
    "    augment=augment, \n",
    "    normalize=True, \n",
    "    debug=debug\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d68a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = CalgaryCampinasDataset(\n",
    "    data_path=data_path, \n",
    "    site=6,\n",
    "    split='validation',\n",
    "    augment=augment, \n",
    "    normalize=True, \n",
    "    debug=debug\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672ef5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsets = []\n",
    "for site in [1,2,3,4,5]:\n",
    "    testsets.append(\n",
    "        CalgaryCampinasDataset(\n",
    "            data_path=data_path, \n",
    "            site=site,\n",
    "            split='all',\n",
    "            augment=augment, \n",
    "            normalize=True, \n",
    "            debug=debug\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a97fe967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = f'../../../pre-trained-tmp/trained_UNets/calgary_unet0_augmentednnUNet_best.pt'\n",
    "state_dict = torch.load(model_path)['model_state_dict']\n",
    "n_chans_out = 1 \n",
    "seg_model = UNet2D(\n",
    "    n_chans_in=1, \n",
    "    n_chans_out=n_chans_out, \n",
    "    n_filters_init=8,\n",
    "    dropout=False\n",
    ")\n",
    "seg_model.load_state_dict(state_dict)\n",
    "seg_model.to(0)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e4a8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [\n",
    "     get_subset(\n",
    "        dataset,\n",
    "        seg_model,\n",
    "        criterion=nn.BCEWithLogitsLoss(reduction='none'),\n",
    "        n_cases=50,\n",
    "        fraction=0.1,\n",
    "        batch_size=32\n",
    "    ) for dataset in [trainset, valset, *testsets]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d383f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disabled_ids = ['shortcut0', 'shortcut1', 'shortcut2']\n",
    "DAEs = nn.ModuleDict(\n",
    "    {'up3': AugResDAE(\n",
    "        in_channels = 64, \n",
    "        in_dim      = 32,\n",
    "        latent_dim  = 256,\n",
    "        depth       = 3,\n",
    "        block_size  = 4)\n",
    "    }\n",
    ")\n",
    "\n",
    "for layer_id in disabled_ids:\n",
    "    DAEs[layer_id] = nn.Identity()\n",
    "\n",
    "model = ModelAdapter(\n",
    "    seg_model=seg_model,\n",
    "    transformations=DAEs,\n",
    "    disabled_ids=disabled_ids,\n",
    "    copy=True\n",
    ")\n",
    "model_path = f'../../../pre-trained-tmp/trained_AEs/calgary_AugResDAE0_localAug_multiImgSingleView_res_balanced_same_best.pt'\n",
    "state_dict = torch.load(model_path)['model_state_dict']\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Remove trainiung hooks, add evaluation hooks\n",
    "model.remove_all_hooks()        \n",
    "model.hook_inference_transformations(model.transformations,\n",
    "                           n_samples=1)\n",
    "# Put model in evaluation state\n",
    "model.to(0)\n",
    "model.eval()\n",
    "model.freeze_seg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b80d5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_downstream_perf(\n",
    "    dataset,\n",
    "    model: nn.Module,\n",
    "    criterion: nn.Module,\n",
    "    device: str = 'cuda:0',\n",
    "    batch_size: int = 1\n",
    "):\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    # collect evaluation per slice and cache\n",
    "    #assert criterion.reduction == 'none'\n",
    "    model.eval()\n",
    "    loss_list = []\n",
    "    for batch in dataloader:\n",
    "        input_  = batch['input'].to(device)\n",
    "        target  = batch['target'].to(device)\n",
    "        net_out = (torch.sigmoid(model(input_)) > 0.5) * 1\n",
    "        loss    = torch.tensor([\n",
    "            criterion(net_out[:1], target).view(input_.shape[0], -1).mean(1),\n",
    "            criterion(net_out[1:], target).view(input_.shape[0], -1).mean(1)\n",
    "        ])\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    return torch.stack(loss_list, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9511ae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9815, 0.9816])\n",
      "tensor([0.9784, 0.9785])\n",
      "tensor([0.9476, 0.9503])\n",
      "tensor([0.9589, 0.9789])\n",
      "tensor([0.9533, 0.9726])\n",
      "tensor([0.9268, 0.9436])\n",
      "tensor([0.8859, 0.9257])\n"
     ]
    }
   ],
   "source": [
    "for subset in subsets:\n",
    "    print(get_downstream_perf(subset, model, DiceScoreCalgary()).mean(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13084a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9589, 0.9789])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e86b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
