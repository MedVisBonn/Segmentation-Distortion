{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ceacc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "import os, sys\n",
    "import time\n",
    "from typing import Iterable, Dict, Callable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Resize, CenterCrop\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "from batchgenerators.utilities.file_and_folder_operations import *\n",
    "from nnunet.training.dataloading.dataset_loading import *\n",
    "from nnunet.training.network_training.nnUNetTrainerV2 import nnUNetTrainerV2\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils import EarlyStopping, epoch_average, average_metrics\n",
    "from dataset import CalgaryCampinasDataset\n",
    "from model.ae import AE\n",
    "from model.unet import UNet2D\n",
    "from model.wrapper import Frankenstein\n",
    "from losses import MNMCriterionAE, CalgaryCriterionAE, SampleDice, UnetDice\n",
    "from trainer.ae_trainer import AETrainerCalgary, AETrainerACDC\n",
    "\n",
    "\n",
    "nnUnet_prefix = '../../../nnUNet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8669d2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19e53f1a0d2483089d4c2e30943b015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../pre-trained-tmp/trained_AEs/calgary_ae_test0_best.pt\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    'debug': True,\n",
    "    'log': False,\n",
    "    'description': 'calgary_ae_test',\n",
    "    'project': 'MICCAI2023',\n",
    "\n",
    "    # Data params\n",
    "    'n': 0,\n",
    "    'root': '../../',\n",
    "    'data_path': 'data/conp-dataset/projects/calgary-campinas/CC359/Reconstructed/',\n",
    "    'train_site': 6,\n",
    "    'unet': 'calgary_unet',\n",
    "    'channel_out': 8,\n",
    "    \n",
    "    # Hyperparams\n",
    "    'batch_size': 64,\n",
    "    'augment': False,\n",
    "    'difference': True,\n",
    "    'loss': 'huber',\n",
    "    'target': 'output',\n",
    "    'identity_layers': ['shortcut0', 'shortcut1', 'shortcut2'],\n",
    "    \n",
    "    # outputs\n",
    "    'plot_dir': '../experiments/unet/calgary/logs/'\n",
    "}\n",
    "\n",
    "\n",
    "description = cfg['description'] + str(cfg['n'])\n",
    "if cfg['augment']:\n",
    "    description += 'augment'\n",
    "\n",
    "### data loading \n",
    "root      = cfg['root']\n",
    "data_path = root + cfg['data_path']\n",
    "train_set = CalgaryCampinasDataset(data_path=data_path, \n",
    "                                   site=cfg['train_site'], \n",
    "                                   augment=cfg['augment'], \n",
    "                                   normalize=True, \n",
    "                                   split='train', \n",
    "                                   debug=cfg['debug'])\n",
    "\n",
    "valid_set = CalgaryCampinasDataset(data_path=data_path, \n",
    "                                   site=cfg['train_site'], \n",
    "                                   normalize=True, \n",
    "                                   split='validation', \n",
    "                                   debug=cfg['debug'])\n",
    "\n",
    "train_loader = DataLoader(train_set, \n",
    "                          batch_size=cfg['batch_size'], \n",
    "                          shuffle=True, \n",
    "                          drop_last=False,\n",
    "                          num_workers=10)\n",
    "\n",
    "valid_loader = DataLoader(valid_set, \n",
    "                          batch_size=cfg['batch_size'], \n",
    "                          shuffle=False, \n",
    "                          drop_last=False,\n",
    "                          num_workers=10)\n",
    "\n",
    "\n",
    "### Unet\n",
    "unet_path = cfg['unet'] + str(cfg['n'])\n",
    "seg_model = UNet2D(n_chans_in=1, n_chans_out=1, n_filters_init=cfg['channel_out']).to(0)\n",
    "model_path = f'{root}pre-trained-tmp/trained_UNets/{unet_path}_best.pt'\n",
    "state_dict = torch.load(model_path)['model_state_dict']\n",
    "seg_model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "### AE Params\n",
    "layer_ids = ['shortcut0', 'shortcut1', 'shortcut2', 'up3']\n",
    "\n",
    "\n",
    "                   # channel, spatial, latent, depth\n",
    "ae_map   = {'up3': [     64,      32,     64,     2]}\n",
    "\n",
    "\n",
    "AEs = nn.ModuleDict({layer_id: AE(in_channels = ae_map[layer_id][0], \n",
    "                                  in_dim      = ae_map[layer_id][1],\n",
    "                                  latent_dim  = ae_map[layer_id][2],\n",
    "                                  depth       = ae_map[layer_id][3],\n",
    "                                  block_size  = 4) \n",
    "                          for layer_id in layer_ids if layer_id not in cfg['identity_layers']})\n",
    "\n",
    "\n",
    "for layer_id in cfg['identity_layers']:\n",
    "    AEs[layer_id] = nn.Identity()\n",
    "\n",
    "model = Frankenstein(seg_model, \n",
    "                     AEs, \n",
    "                     disabled_ids=cfg['identity_layers'],\n",
    "                     copy=True)\n",
    "\n",
    "criterion = CalgaryCriterionAE(loss=cfg['loss'])\n",
    "\n",
    "eval_metrics = {'Sample Volumetric Dice': SampleDice(data='calgary'),\n",
    "                'UNet Volumetric Dice': UnetDice(data='calgary')}\n",
    "\n",
    "trainer = AETrainerCalgary(model=model, \n",
    "                           unet=seg_model, \n",
    "                           criterion=criterion, \n",
    "                           train_loader=train_loader, \n",
    "                           valid_loader=valid_loader, \n",
    "                           root=root,\n",
    "                           target=cfg['target'],\n",
    "                           description=description,\n",
    "                           lr=1e-4, \n",
    "                           eval_metrics=eval_metrics, \n",
    "                           log=cfg['log'],\n",
    "                           n_epochs=1,\n",
    "                           patience=4) #20\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b96b274a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n",
      "loading all case properties\n",
      "2023-10-10 08:18:13.187382: Using splits from existing split file: ../../../nnUNet/data/nnUNet_preprocessed/Task500_ACDC/splits_final.pkl\n",
      "2023-10-10 08:18:13.202848: The split file contains 5 splits.\n",
      "2023-10-10 08:18:13.203122: Desired fold for training: 0\n",
      "2023-10-10 08:18:13.203817: This split has 160 training and 40 validation cases.\n",
      "unpacking dataset\n",
      "done\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5e974b415e4edc89a14d60e8fa73aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "../../pre-trained-tmp/trained_AEs/acdc_ae_test_best.pt\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "        'debug': True,\n",
    "        'log': False,\n",
    "        'description': f'acdc_ae_test', #'mms_vae_for_nnUNet_fc3_0_bs50',\n",
    "        'project': 'MICCAI2023',\n",
    "\n",
    "        # Data params\n",
    "        'n': 0,\n",
    "        'root': '../../',\n",
    "        'data_path': 'data/mnm/',\n",
    "        'train_vendor': 'B',\n",
    "        'unet': f'acdc_unet8_0',\n",
    "        'channel_out': 8,\n",
    "\n",
    "        # Hyperparams\n",
    "        'batch_size': 32,\n",
    "        'augment': False,\n",
    "        'difference': True,\n",
    "        'loss': 'huber',  # huber or ce\n",
    "        'target': 'output', #gt or output\n",
    "        'disabled_ids': ['shortcut0', 'shortcut1', 'shortcut2']\n",
    "}\n",
    "\n",
    "description = cfg['description']\n",
    "root = cfg['root']\n",
    "\n",
    "# Unet\n",
    "unet_path = cfg['unet'] # + str(cfg['n'])\n",
    "unet = UNet2D(n_chans_in=1, n_chans_out=4, n_filters_init=cfg['channel_out']).to(0)\n",
    "model_path = f'{root}pre-trained-tmp/trained_UNets/{unet_path}_best.pt'\n",
    "state_dict = torch.load(model_path)['model_state_dict']\n",
    "unet.load_state_dict(state_dict)\n",
    "\n",
    "### Dataloader\n",
    "## Initialize trainer to get data loaders with data augmentations from training\n",
    "pkl_file          = nnUnet_prefix + 'data/nnUNet_preprocessed/Task500_ACDC/nnUNetPlansv2.1_plans_2D.pkl'\n",
    "fold              = 0\n",
    "output_folder     = nnUnet_prefix + 'results/nnUnet/nnUNet/2d/Task027_ACDC/nnUNetTrainerV2__nnUNetPlansv2.1/'\n",
    "dataset_directory = nnUnet_prefix + 'data/nnUNet_preprocessed/Task500_ACDC'\n",
    "\n",
    "trainer = nnUNetTrainerV2(pkl_file, 0, output_folder, dataset_directory)\n",
    "trainer.initialize()\n",
    "\n",
    "train_loader = trainer.tr_gen\n",
    "valid_loader = trainer.val_gen\n",
    "\n",
    "\n",
    "### VAE Params\n",
    "layer_ids = ['shortcut0', 'shortcut1', 'shortcut2', 'up3']\n",
    "\n",
    "                   #    channel, spatial, latent,  depth, block \n",
    "ae_map   = {'up3': [        64,      32,    128,     2,      4]}\n",
    "\n",
    "cfg['ae_map'] = ae_map\n",
    "if cfg['log']:\n",
    "    run = wandb.init(reinit=True, \n",
    "                     name=cfg['description'],\n",
    "                     project=cfg['project'], \n",
    "                     config=cfg)\n",
    "    cfg = wandb.config\n",
    "\n",
    "\n",
    "AEs = nn.ModuleDict({'up3': AE(in_channels = ae_map['up3'][0], \n",
    "                               in_dim      = ae_map['up3'][1],\n",
    "                               latent_dim  = ae_map['up3'][2],\n",
    "                               depth       = ae_map['up3'][3],\n",
    "                               block_size  = ae_map['up3'][4])})\n",
    "\n",
    "for layer_id in cfg['disabled_ids']:\n",
    "     AEs[layer_id] = nn.Identity()\n",
    "\n",
    "\n",
    "model = Frankenstein(unet, \n",
    "                     AEs, \n",
    "                     disabled_ids=cfg['disabled_ids'],\n",
    "                     copy=True)\n",
    "\n",
    "model.cuda()\n",
    "print()\n",
    "criterion    = MNMCriterionAE(loss=cfg['loss'], diff=cfg['difference'])\n",
    "eval_metrics = {'Sample Volumetric Dice': SampleDice(data='MNM'),\n",
    "                'UNet Volumetric Dice': UnetDice(data='MNM')}\n",
    "\n",
    "ae_trainer = AETrainerACDC(model=model, \n",
    "                           unet=unet, \n",
    "                           criterion=criterion, \n",
    "                           train_loader=train_loader, \n",
    "                           valid_loader=valid_loader, \n",
    "                           num_batches_per_epoch=trainer.num_batches_per_epoch,\n",
    "                           num_val_batches_per_epoch=trainer.num_val_batches_per_epoch,\n",
    "                           root=root,\n",
    "                           target=cfg['target'],\n",
    "                           description=description,\n",
    "                           lr=1e-4, \n",
    "                           eval_metrics=eval_metrics, \n",
    "                           log=cfg['log'],\n",
    "                           n_epochs=1, \n",
    "                           patience=8)\n",
    "\n",
    "\n",
    "ae_trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b5da29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
