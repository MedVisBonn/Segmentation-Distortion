{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8ca02a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "import os, sys\n",
    "import time\n",
    "from typing import Iterable, Dict, Callable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Resize, CenterCrop\n",
    "from torchmetrics import SpearmanCorrCoef\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "from batchgenerators.utilities.file_and_folder_operations import *\n",
    "from nnunet.training.dataloading.dataset_loading import *\n",
    "from nnunet.training.network_training.nnUNetTrainerV2 import nnUNetTrainerV2\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils import EarlyStopping, epoch_average, average_metrics, UMapGenerator, volume_collate\n",
    "from dataset import CalgaryCampinasDataset, ACDCDataset, MNMDataset\n",
    "from model.ae import AE\n",
    "from model.unet import UNet2D, UNetEnsemble\n",
    "from losses import MNMCriterionAE, CalgaryCriterionAE, SampleDice, UnetDice, DiceScoreCalgary, DiceScoreMMS #\n",
    "from trainer.ae_trainer import AETrainerCalgary, AETrainerACDC\n",
    "\n",
    "\n",
    "nnUnet_prefix = '../../../nnUNet/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d8d17171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UNetEnsemble(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        unets: List,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ensemble = nn.ModuleList(unets)\n",
    "\n",
    "    def forward(self, x, reduce='none'):\n",
    "        x_out = torch.cat([module(x.clone()) for module in self.ensemble])\n",
    "        #print(x_out.shape)\n",
    "        if reduce=='none':\n",
    "            return x_out\n",
    "        elif reduce=='mean':\n",
    "            return x_out.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "cb1c11ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'debug': False,\n",
    "    'log': True,\n",
    "    'description': 'calgary_ae_test',\n",
    "    'project': 'MICCAI2023',\n",
    "\n",
    "    # Data params\n",
    "    'n': 0,\n",
    "    'root': '../../',\n",
    "    'data_path': 'data/conp-dataset/projects/calgary-campinas/CC359/Reconstructed/',\n",
    "    'train_site': 6,\n",
    "    'unet': 'calgary_unet',\n",
    "    'channel_out': 8,\n",
    "    \n",
    "    # Hyperparams\n",
    "    'batch_size': 1,\n",
    "    'augment': False,\n",
    "    'difference': True,\n",
    "    'loss': 'huber',\n",
    "    'target': 'output',\n",
    "    'identity_layers': ['shortcut0', 'shortcut1', 'shortcut2'],\n",
    "    \n",
    "    # outputs\n",
    "    'plot_dir': '../experiments/unet/calgary/logs/'\n",
    "}\n",
    "\n",
    "\n",
    "description = cfg['description'] + str(cfg['n'])\n",
    "if cfg['augment']:\n",
    "    description += 'augment'\n",
    "\n",
    "### data loading \n",
    "root      = cfg['root']\n",
    "data_path = root + cfg['data_path']\n",
    "train_set = CalgaryCampinasDataset(data_path=data_path, \n",
    "                                   site=cfg['train_site'], \n",
    "                                   augment=cfg['augment'], \n",
    "                                   normalize=True, \n",
    "                                   split='train', \n",
    "                                   debug=cfg['debug'])\n",
    "\n",
    "valid_set = CalgaryCampinasDataset(data_path=data_path, \n",
    "                                   site=cfg['train_site'], \n",
    "                                   normalize=True,\n",
    "                                   volume_wise=True,\n",
    "                                   split='validation', \n",
    "                                   debug=cfg['debug'])\n",
    "\n",
    "\n",
    "test_set = CalgaryCampinasDataset(data_path=data_path, \n",
    "                                  site=1, \n",
    "                                  normalize=True, \n",
    "                                  volume_wise=True,\n",
    "                                  split='all', \n",
    "                                  debug=cfg['debug'])\n",
    "\n",
    "train_loader = DataLoader(train_set, \n",
    "                          batch_size=cfg['batch_size'], \n",
    "                          shuffle=True, \n",
    "                          drop_last=False,\n",
    "                          num_workers=10)\n",
    "\n",
    "valid_loader = DataLoader(valid_set, \n",
    "                          batch_size=cfg['batch_size'], \n",
    "                          shuffle=False, \n",
    "                          drop_last=False,\n",
    "                          num_workers=1,\n",
    "                          collate_fn=volume_collate)\n",
    "\n",
    "test_loader = DataLoader(test_set, \n",
    "                         batch_size=cfg['batch_size'], \n",
    "                         shuffle=False, \n",
    "                         drop_last=False,\n",
    "                         num_workers=1,\n",
    "                         collate_fn=volume_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "03f6d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = CalgaryCampinasDataset(data_path=data_path, \n",
    "                                  site=2, \n",
    "                                  normalize=True, \n",
    "                                  volume_wise=True,\n",
    "                                  split='all', \n",
    "                                  debug=cfg['debug'])\n",
    "\n",
    "test_loader = DataLoader(test_set, \n",
    "                         batch_size=cfg['batch_size'], \n",
    "                         shuffle=False, \n",
    "                         drop_last=False,\n",
    "                         num_workers=1,\n",
    "                         collate_fn=volume_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1b060159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - load unets\n",
    "unets = []\n",
    "unet_path = cfg['unet']\n",
    "\n",
    "for i in range(10):\n",
    "    seg_model = UNet2D(n_chans_in=1, n_chans_out=1, n_filters_init=cfg['channel_out'])\n",
    "    model_path = f'{root}pre-trained-tmp/trained_UNets/{unet_path + str(i)}_best.pt'\n",
    "    state_dict = torch.load(model_path)['model_state_dict']\n",
    "    seg_model.load_state_dict(state_dict)\n",
    "    unets.append(seg_model)\n",
    "    \n",
    "# - verify that we have different models\n",
    "param_sums = torch.tensor(\n",
    "    [torch.tensor(\n",
    "        [p.data.sum() for p in unets[i].parameters()]).sum()\n",
    "     for i in range(10)]\n",
    ")\n",
    "assert torch.any(param_sums.mean() != param_sums)\n",
    "\n",
    "# - build ensemble\n",
    "ensemble = UNetEnsemble(unets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c068907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleEntropyDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    Evaluation class for OOD and ESCE tasks based on AEs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module, \n",
    "        net_out: str,\n",
    "        valid_loader: DataLoader,\n",
    "        criterion: nn.Module,\n",
    "        device: str = 'cuda:0'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net_out = net_out\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        torch.manual_seed(42)\n",
    "        self.ensemble_compositions = torch.cat([torch.arange(10).view(10,1), \n",
    "                                                torch.randint(0, 9, (10, 4))],\n",
    "                                               dim=1)\n",
    "        # Remove trainiung hooks, add evaluation hooks\n",
    "        # self.model.remove_all_hooks()        \n",
    "        \n",
    "        self.valid_loader = valid_loader\n",
    "        self.criterion = criterion\n",
    "        self.umap_generator = UMapGenerator(method='probs',\n",
    "                                            net_out=net_out)\n",
    "        \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def testset_ood_detection(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        \n",
    "        if not hasattr(self, 'threshold'):\n",
    "            valid_dists = []\n",
    "            for batch in self.valid_loader:\n",
    "                input_ = batch['input'].to(0)\n",
    "                net_out = self.forward(input_.to(self.device))\n",
    "                score = torch.norm(umap).cpu()\n",
    "                valid_dists.append(score)\n",
    "                    \n",
    "            self.threshold = 0\n",
    "            valid_dists = torch.tensor(valid_dists)\n",
    "            self.threshold = torch.sort(valid_dists)[0][len(valid_dists) - (len(valid_dists) // 20) - 1]\n",
    "        \n",
    "        test_dists = []\n",
    "        for batch in test_loader:\n",
    "            input_ = batch['input']\n",
    "\n",
    "            net_out = self.forward(input_.to(self.device))\n",
    "\n",
    "            score = torch.norm(umap).cpu()\n",
    "            test_dists.append(score)\n",
    "            \n",
    "        test_dists = torch.tensor(test_dists).cpu()\n",
    "        accuracy = (test_dists > self.threshold).sum() / len(test_dists)\n",
    "        \n",
    "        return accuracy    \n",
    "        \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def testset_correlation(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        corr_coeffs = [SpearmanCorrCoef() for _ in range(10)]\n",
    "        losses = []\n",
    "        for batch in tqdm(test_loader):\n",
    "            input_ = batch['input'].to(0)\n",
    "            #print(input_.shape)\n",
    "            target = batch['target']\n",
    "            \n",
    "            if self.net_out == 'calgary':\n",
    "                net_out_volume = []\n",
    "                #umap_volume  = []\n",
    "\n",
    "                for input_chunk in input_:\n",
    "                    net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "                    net_out_volume.append(net_out.detach().cpu())\n",
    "                    #umap_volume.append(umap)\n",
    "                    \n",
    "                net_out = torch.stack(net_out_volume, dim=0)\n",
    "                #print(net_out.shape)\n",
    "                #umap = torch.cat(umap_volume, dim=0)\n",
    "            \n",
    "            if self.net_out == 'mms':\n",
    "                target[target == -1] = 0\n",
    "                # convert to one-hot encoding\n",
    "                target = F.one_hot(target.long(), num_classes=4).squeeze(1).permute(0,3,1,2)\n",
    "                net_out = self.forward(input_.to(self.device))\n",
    "            \n",
    "            #score = torch.norm(umap).cpu()\n",
    "            \n",
    "            for i, corr_coeff in enumerate(corr_coeffs):\n",
    "                ensemble_idxs = self.ensemble_compositions[i]\n",
    "                #umap = self.umap_generator(net_out[ensemble_idxs].mean(0, keepdim=True))\n",
    "                \n",
    "                if self.net_out == 'calgary':\n",
    "                    loss = self.criterion(net_out[:, i:i+1].cpu(), target.cpu())\n",
    "                    umap_volume  = []\n",
    "                    for slc in net_out:\n",
    "                        umap = self.umap_generator(slc[ensemble_idxs].mean(0, keepdim=True))\n",
    "                        #break\n",
    "                        umap_volume.append(umap)\n",
    "                    umap = torch.cat(umap_volume, dim=0)\n",
    "                \n",
    "                if self.net_out == 'mms':\n",
    "                    loss = self.criterion(net_out[i:i+1].cpu(), target.cpu())\n",
    "                    umap = self.umap_generator(net_out[ensemble_idxs].mean(0, keepdim=True))\n",
    "                    \n",
    "                score = torch.norm(umap).cpu()    \n",
    "                loss = loss.mean().cpu().float()\n",
    "                corr_coeff.update(score, 1-loss)\n",
    "                #losses.append(1-loss.view(1))\n",
    "            \n",
    "        return corr_coeffs\n",
    "\n",
    "    \n",
    "    @torch.no_grad()  \n",
    "    def forward(self, input_: torch.Tensor) -> torch.Tensor:\n",
    "        self.model.eval()\n",
    "        net_out = self.model(input_)\n",
    "        #umap = self.umap_generator(net_out.mean(0, keepdim=True))\n",
    "        #score = torch.linalg.norm(umap, dim=(-2, -1))\n",
    "        return net_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f897e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EnsembleEntropyDetector(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Evaluation class for OOD and ESCE tasks based on AEs.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(\n",
    "#         self, \n",
    "#         model: nn.Module, \n",
    "#         net_out: str,\n",
    "#         valid_loader: DataLoader,\n",
    "#         criterion: nn.Module,\n",
    "#         device: str = 'cuda:0'\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.net_out = net_out\n",
    "#         self.device = device\n",
    "#         self.model = model.to(device)\n",
    "#         # Remove trainiung hooks, add evaluation hooks\n",
    "#         # self.model.remove_all_hooks()        \n",
    "        \n",
    "#         self.valid_loader = valid_loader\n",
    "#         self.criterion = criterion\n",
    "#         self.umap_generator = UMapGenerator(method='probs',\n",
    "#                                             net_out=net_out)\n",
    "        \n",
    "        \n",
    "#     @torch.no_grad()\n",
    "#     def testset_ood_detection(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "        \n",
    "#         if not hasattr(self, 'threshold'):\n",
    "#             valid_dists = []\n",
    "#             for batch in self.valid_loader:\n",
    "#                 input_ = batch['input'].to(0)\n",
    "                \n",
    "#                 if self.net_out == 'calgary':\n",
    "#                     net_out_volume = []\n",
    "#                     umap_volume  = []\n",
    "\n",
    "#                     for input_chunk in input_:\n",
    "#                         umap, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "#                         net_out_volume.append(net_out.detach().cpu())\n",
    "#                         umap_volume.append(umap)\n",
    "\n",
    "#                     net_out = torch.cat(net_out_volume, dim=0)\n",
    "#                     umap = torch.cat(umap_volume, dim=0)\n",
    "                    \n",
    "#                 if self.net_out == 'mms':\n",
    "#                     umap, net_out = self.forward(input_.to(self.device))\n",
    "#                 score = torch.norm(umap).cpu()\n",
    "#                 valid_dists.append(score)\n",
    "                    \n",
    "#             self.threshold = 0\n",
    "#             valid_dists = torch.tensor(valid_dists)\n",
    "#             self.threshold = torch.sort(valid_dists)[0][len(valid_dists) - (len(valid_dists) // 20) - 1]\n",
    "        \n",
    "#         test_dists = []\n",
    "#         for batch in test_loader:\n",
    "#             input_ = batch['input']\n",
    "\n",
    "#             if self.net_out == 'calgary':\n",
    "#                 net_out_volume = []\n",
    "#                 umap_volume  = []\n",
    "\n",
    "#                 for input_chunk in input_:\n",
    "#                     umap, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "#                     net_out_volume.append(net_out.detach().cpu())\n",
    "#                     umap_volume.append(umap)\n",
    "\n",
    "#                 net_out = torch.cat(net_out_volume, dim=0)\n",
    "#                 umap = torch.cat(umap_volume, dim=0)\n",
    "\n",
    "#             if self.net_out == 'mms':\n",
    "#                 umap, net_out = self.forward(input_.to(self.device))\n",
    "\n",
    "#             score = torch.norm(umap).cpu()\n",
    "#             test_dists.append(score)\n",
    "            \n",
    "#         test_dists = torch.tensor(test_dists).cpu()\n",
    "#         accuracy = (test_dists > self.threshold).sum() / len(test_dists)\n",
    "        \n",
    "#         return accuracy    \n",
    "        \n",
    "    \n",
    "#     @torch.no_grad()\n",
    "#     def testset_correlation(self, test_loader: DataLoader) -> Dict[str, torch.Tensor]:\n",
    "#         corr_coeffs = [SpearmanCorrCoef() for _ in range(10)]\n",
    "#         losses = []\n",
    "#         for batch in tqdm(test_loader):\n",
    "#             input_ = batch['input'].to(0)\n",
    "#             target = batch['target']\n",
    "            \n",
    "#             if self.net_out == 'calgary':\n",
    "#                 net_out_volume = []\n",
    "#                 umap_volume  = []\n",
    "\n",
    "#                 for input_chunk in input_:\n",
    "#                     umap, net_out = self.forward(input_chunk.unsqueeze(0).to(self.device))\n",
    "#                     net_out_volume.append(net_out.detach().cpu())\n",
    "#                     umap_volume.append(umap)\n",
    "                    \n",
    "#                 net_out = torch.stack(net_out_volume, dim=0)\n",
    "#                 umap = torch.cat(umap_volume, dim=0)\n",
    "            \n",
    "#             if self.net_out == 'mms':\n",
    "#                 target[target == -1] = 0\n",
    "#                 # convert to one-hot encoding\n",
    "#                 target = F.one_hot(target.long(), num_classes=4).squeeze(1).permute(0,3,1,2)\n",
    "#                 umap, net_out = self.forward(input_.to(self.device))\n",
    "            \n",
    "#             score = torch.norm(umap).cpu()\n",
    "            \n",
    "#             for i, corr_coeff in enumerate(corr_coeffs):\n",
    "#                 if self.net_out == 'calgary':\n",
    "#                     loss = self.criterion(net_out[:, i:i+1].cpu(), target.cpu())\n",
    "                \n",
    "#                 if self.net_out == 'mms':\n",
    "#                     loss = self.criterion(net_out[i:i+1].cpu(), target.cpu())\n",
    "#                 loss = loss.mean().cpu().float()\n",
    "#                 corr_coeff.update(score, 1-loss)\n",
    "#                 #losses.append(1-loss.view(1))\n",
    "            \n",
    "#         return corr_coeffs\n",
    "\n",
    "    \n",
    "#     @torch.no_grad()  \n",
    "#     def forward(self, input_: torch.Tensor) -> torch.Tensor:\n",
    "#         self.model.eval()\n",
    "#         net_out = self.model(input_)\n",
    "#         umap = self.umap_generator(net_out.mean(0, keepdim=True))\n",
    "#         #score = torch.linalg.norm(umap, dim=(-2, -1))\n",
    "#         return umap, net_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3e354c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = EnsembleEntropyDetector(model=ensemble, \n",
    "                                   net_out='calgary', \n",
    "                                   valid_loader=valid_loader, \n",
    "                                   criterion=DiceScoreCalgary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3812be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_acc = detector.testset_ood_detection(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "56a81e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lennartz/anaconda3/envs/default/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b0d5cf57744543ab16610365334019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_cor = detector.testset_correlation(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7d8f5282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SpearmanCorrCoef(),\n",
       " SpearmanCorrCoef(),\n",
       " SpearmanCorrCoef(),\n",
       " SpearmanCorrCoef(),\n",
       " SpearmanCorrCoef(),\n",
       " SpearmanCorrCoef(),\n",
       " SpearmanCorrCoef(),\n",
       " SpearmanCorrCoef(),\n",
       " SpearmanCorrCoef(),\n",
       " SpearmanCorrCoef()]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8ba5ad1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6294)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([tmp_cor[i].compute() for i in range(10)]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b60a4f8",
   "metadata": {},
   "source": [
    "'1'\n",
    "tensor(0.8288), tensor(0.8383), tensor(0.8342), tensor(0.8465), tensor(0.8315), tensor(0.8254), tensor(0.8407), tensor(0.8318), tensor(0.8290), tensor(0.8295)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f1e43",
   "metadata": {},
   "source": [
    "'2' : 0.6854\n",
    "tensor(0.7273), tensor(0.7371), tensor(0.6117), tensor(0.7785), tensor(0.7030), tensor(0.6041), tensor(0.6962), tensor(0.6205), tensor(0.6614), tensor(0.7140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "844610ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n",
      "loading all case properties\n",
      "loading dataset\n",
      "loading all case properties\n",
      "loading dataset\n",
      "loading all case properties\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "        'debug': False,\n",
    "        'log': False,\n",
    "        'description': f'acdc_ae_test', #'mms_vae_for_nnUNet_fc3_0_bs50',\n",
    "        'project': 'MICCAI2023',\n",
    "\n",
    "        # Data params\n",
    "        'n': 0,\n",
    "        'root': '../../',\n",
    "        'data_path': 'data/mnm/',\n",
    "        'train_vendor': 'B',\n",
    "        'unet': f'acdc_unet8_',\n",
    "        'channel_out': 8,\n",
    "\n",
    "        # Hyperparams\n",
    "        'batch_size': 32,\n",
    "        'augment': False,\n",
    "        'difference': True,\n",
    "        'loss': 'huber',  # huber or ce\n",
    "        'target': 'output', #gt or output\n",
    "        'disabled_ids': ['shortcut0', 'shortcut1', 'shortcut2']\n",
    "}\n",
    "\n",
    "description = cfg['description']\n",
    "root = cfg['root']\n",
    "debug = cfg['debug']\n",
    "\n",
    "data = 'data/mnm/'\n",
    "data_path = root + data\n",
    "train_set = ACDCDataset(data='train', \n",
    "                        debug=debug)\n",
    "\n",
    "train_loader = DataLoader(train_set, \n",
    "                          batch_size=32, \n",
    "                          shuffle=False,\n",
    "                          drop_last=False,\n",
    "                          num_workers=10)\n",
    "\n",
    "valid_set = ACDCDataset(data='val', \n",
    "                        debug=debug)\n",
    "\n",
    "valid_loader = DataLoader(valid_set, \n",
    "                          batch_size=1, \n",
    "                          shuffle=False, \n",
    "                          drop_last=False, \n",
    "                          num_workers=10)\n",
    "\n",
    "test_set = MNMDataset(vendor='B', \n",
    "                      debug=debug)\n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_set, \n",
    "                         batch_size=1, \n",
    "                         shuffle=False, \n",
    "                         drop_last=False,\n",
    "                         num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "89c4e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - load unets\n",
    "unets = []\n",
    "unet_path = cfg['unet']\n",
    "\n",
    "for i in range(10):\n",
    "    seg_model = UNet2D(n_chans_in=1, n_chans_out=4, n_filters_init=cfg['channel_out'])\n",
    "    model_path = f'{root}pre-trained-tmp/trained_UNets/{unet_path + str(i)}_best.pt'\n",
    "    state_dict = torch.load(model_path)['model_state_dict']\n",
    "    seg_model.load_state_dict(state_dict)\n",
    "    unets.append(seg_model)\n",
    "    \n",
    "# - verify that we have different models\n",
    "param_sums = torch.tensor(\n",
    "    [torch.tensor(\n",
    "        [p.data.sum() for p in unets[i].parameters()]).sum()\n",
    "     for i in range(10)]\n",
    ")\n",
    "assert torch.any(param_sums.mean() != param_sums)\n",
    "\n",
    "# - build ensemble\n",
    "ensemble = UNetEnsemble(unets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d7b07a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = EnsembleEntropyDetector(model=ensemble, \n",
    "                                   net_out='mms', \n",
    "                                   valid_loader=valid_loader, \n",
    "                                   criterion=DiceScoreMMS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dddfb3a1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [101]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tmp_acc \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtestset_ood_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [99]\u001b[0m, in \u001b[0;36mEnsembleEntropyDetector.testset_ood_detection\u001b[0;34m(self, test_loader)\u001b[0m\n\u001b[1;32m     45\u001b[0m     umap \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(umap_volume, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet_out \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmms\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 48\u001b[0m     umap, net_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m score \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(umap)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     50\u001b[0m valid_dists\u001b[38;5;241m.\u001b[39mappend(score)\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [99]\u001b[0m, in \u001b[0;36mEnsembleEntropyDetector.forward\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()  \n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 124\u001b[0m     net_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     umap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mumap_generator(net_out\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m#score = torch.linalg.norm(umap, dim=(-2, -1))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [91]\u001b[0m, in \u001b[0;36mUNetEnsemble.forward\u001b[0;34m(self, x, reduce)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     x_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([module(x\u001b[38;5;241m.\u001b[39mclone()) \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensemble])\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#print(x_out.shape)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reduce\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Input \u001b[0;32mIn [91]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     x_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensemble])\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#print(x_out.shape)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reduce\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/repos/Segmentation-Distortion/src/demos/../model/unet.py:185\u001b[0m, in \u001b[0;36mUNet2D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    183\u001b[0m x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_path(x)\n\u001b[1;32m    184\u001b[0m x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattachment(x0)\n\u001b[0;32m--> 185\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown2(x1)\n\u001b[1;32m    187\u001b[0m x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown3(x2)\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/nn/modules/module.py:1124\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1121\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1125\u001b[0m     forward_call \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[1;32m   1126\u001b[0m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tmp_acc = detector.testset_ood_detection(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0e4b4fa9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2664d0ef522422895389608db99fa71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2642 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [169]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tmp_cor \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtestset_correlation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [167]\u001b[0m, in \u001b[0;36mEnsembleEntropyDetector.testset_correlation\u001b[0;34m(self, test_loader)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# convert to one-hot encoding\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     target \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(target\u001b[38;5;241m.\u001b[39mlong(), num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m     net_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m#score = torch.norm(umap).cpu()\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, corr_coeff \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(corr_coeffs):\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [167]\u001b[0m, in \u001b[0;36mEnsembleEntropyDetector.forward\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()  \n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     net_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(input_)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m#umap = self.umap_generator(net_out.mean(0, keepdim=True))\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m#score = torch.linalg.norm(umap, dim=(-2, -1))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/nn/modules/module.py:1858\u001b[0m, in \u001b[0;36mModule.eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m: T) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m   1843\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sets the module in evaluation mode.\u001b[39;00m\n\u001b[1;32m   1844\u001b[0m \n\u001b[1;32m   1845\u001b[0m \u001b[38;5;124;03m    This has any effect only on certain modules. See documentations of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1858\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/nn/modules/module.py:1839\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1837\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m-> 1839\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/nn/modules/module.py:1839\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1837\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m-> 1839\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "    \u001b[0;31m[... skipping similar frames: Module.train at line 1839 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/nn/modules/module.py:1839\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1837\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m-> 1839\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/nn/modules/module.py:1837\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mode, \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m   1836\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining mode is expected to be boolean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1837\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m   1839\u001b[0m     module\u001b[38;5;241m.\u001b[39mtrain(mode)\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/nn/modules/module.py:1220\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1217\u001b[0m                 d\u001b[38;5;241m.\u001b[39mdiscard(name)\n\u001b[1;32m   1219\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mParameter\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot assign parameters before Module.__init__() call\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/default/lib/python3.8/site-packages/torch/nn/parameter.py:11\u001b[0m, in \u001b[0;36m_ParameterMeta.__instancecheck__\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__instancecheck__\u001b[39m(\u001b[38;5;28mself\u001b[39m, instance):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__instancecheck__\u001b[39m(instance) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(instance, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_param\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tmp_cor = detector.testset_correlation(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "820db9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.2339),\n",
       " tensor(0.1467),\n",
       " tensor(0.2289),\n",
       " tensor(0.1222),\n",
       " tensor(0.1496),\n",
       " tensor(0.1020),\n",
       " tensor(0.2445),\n",
       " tensor(0.1846),\n",
       " tensor(0.0649),\n",
       " tensor(0.1746)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'B'\n",
    "[tmp_cor[i].compute() for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "14ffa5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.2736),\n",
       " tensor(0.2631),\n",
       " tensor(0.3509),\n",
       " tensor(0.0849),\n",
       " tensor(0.3006),\n",
       " tensor(0.2418),\n",
       " tensor(0.3077),\n",
       " tensor(0.2769),\n",
       " tensor(0.1515),\n",
       " tensor(0.2748)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tmp_cor[i].compute() for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfa0639",
   "metadata": {},
   "source": [
    "'B'\n",
    "tensor(0.2339), tensor(0.1467), tensor(0.2289), tensor(0.1222), tensor(0.1496), tensor(0.1020), tensor(0.2445), tensor(0.1846), tensor(0.0649), tensor(0.1746)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3fb2b9",
   "metadata": {},
   "source": [
    "'A'\n",
    "tensor(0.2736), tensor(0.2631), tensor(0.3509), tensor(0.0849), tensor(0.3006), tensor(0.2418), tensor(0.3077), tensor(0.2769), tensor(0.1515), tensor(0.2748)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529a15e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c881b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "227a33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones((10,10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bb54d4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 10])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [0,1,3]\n",
    "x[:, idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d1d65dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c43b7820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 7, 5, 3],\n",
       "        [7, 2, 6, 2],\n",
       "        [7, 8, 0, 7],\n",
       "        [3, 6, 4, 1],\n",
       "        [1, 3, 0, 4],\n",
       "        [4, 5, 3, 6],\n",
       "        [6, 6, 1, 2],\n",
       "        [0, 2, 7, 6],\n",
       "        [3, 8, 3, 0],\n",
       "        [5, 4, 0, 2]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 9, (10, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d522f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.cat([torch.arange(10).view(10,1), torch.randint(0, 9, (10, 4))], dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f8a9a4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "257ad60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5, 2, 2, 7]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d1a20a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, [0, 5, 2, 2, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3ad299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
